{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from loadFilteredData import *\n",
    "#loading all data\n",
    "origImg = loadAllTopicData('original')\n",
    "gingham = loadAllTopicData('gingham')\n",
    "clarendon = loadAllTopicData('clarendon')\n",
    "juno = loadAllTopicData('juno')\n",
    "lark = loadAllTopicData('lark')\n",
    "gotham = loadAllTopicData('gotham')\n",
    "reyes = loadAllTopicData('reyes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "X, y, Xtest, ytest = createData([origImg, clarendon, gingham, juno, lark, gotham, reyes], .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50400, 128, 128, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threeChannelHistogram(images, bins):\n",
    "    histograms = []\n",
    "    for image in images:\n",
    "        redHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        greenHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        blueHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        #print(np.hstack((redHist, greenHist, blueHist)))\n",
    "        histograms.append(np.hstack((redHist, greenHist, blueHist)))\n",
    "        #histograms.append(np.histogram(image, bins=bins, range=(0, 255))[0])\n",
    "    return np.stack(histograms)\n",
    "bins = 300\n",
    "categories = 7\n",
    "Xhist = threeChannelHistogram(X, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=bins * 3, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(categories, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50400/50400 [==============================] - 3s 69us/step - loss: 1.7461 - acc: 0.3587\n",
      "Epoch 2/100\n",
      "50400/50400 [==============================] - 3s 62us/step - loss: 1.1441 - acc: 0.5238\n",
      "Epoch 3/100\n",
      "50400/50400 [==============================] - 3s 57us/step - loss: 1.0419 - acc: 0.5605\n",
      "Epoch 4/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.9871 - acc: 0.5859\n",
      "Epoch 5/100\n",
      "50400/50400 [==============================] - 3s 56us/step - loss: 0.9537 - acc: 0.6110\n",
      "Epoch 6/100\n",
      "50400/50400 [==============================] - 3s 56us/step - loss: 0.9258 - acc: 0.6279\n",
      "Epoch 7/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.8784 - acc: 0.6609\n",
      "Epoch 8/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.8488 - acc: 0.6767\n",
      "Epoch 9/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.8185 - acc: 0.6873\n",
      "Epoch 10/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.8002 - acc: 0.6956\n",
      "Epoch 11/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.7876 - acc: 0.7023\n",
      "Epoch 12/100\n",
      "50400/50400 [==============================] - 3s 56us/step - loss: 0.7742 - acc: 0.7058\n",
      "Epoch 13/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.7624 - acc: 0.7124\n",
      "Epoch 14/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.7535 - acc: 0.7176\n",
      "Epoch 15/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.7462 - acc: 0.7179\n",
      "Epoch 16/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.7391 - acc: 0.7230\n",
      "Epoch 17/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.7306 - acc: 0.7268\n",
      "Epoch 18/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.7211 - acc: 0.7277\n",
      "Epoch 19/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.7202 - acc: 0.7282\n",
      "Epoch 20/100\n",
      "50400/50400 [==============================] - 3s 57us/step - loss: 0.7187 - acc: 0.7315\n",
      "Epoch 21/100\n",
      "50400/50400 [==============================] - 3s 57us/step - loss: 0.7119 - acc: 0.7321\n",
      "Epoch 22/100\n",
      "50400/50400 [==============================] - 3s 58us/step - loss: 0.7078 - acc: 0.7329\n",
      "Epoch 23/100\n",
      "50400/50400 [==============================] - 3s 58us/step - loss: 0.7041 - acc: 0.7359\n",
      "Epoch 24/100\n",
      "50400/50400 [==============================] - 3s 56us/step - loss: 0.6966 - acc: 0.7364\n",
      "Epoch 25/100\n",
      "50400/50400 [==============================] - 3s 56us/step - loss: 0.6931 - acc: 0.7396\n",
      "Epoch 26/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6942 - acc: 0.7399\n",
      "Epoch 27/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.6879 - acc: 0.7402\n",
      "Epoch 28/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.6850 - acc: 0.7424\n",
      "Epoch 29/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.6795 - acc: 0.7437\n",
      "Epoch 30/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6796 - acc: 0.7437\n",
      "Epoch 31/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6796 - acc: 0.7451\n",
      "Epoch 32/100\n",
      "50400/50400 [==============================] - 3s 56us/step - loss: 0.6733 - acc: 0.7462\n",
      "Epoch 33/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.6729 - acc: 0.7464\n",
      "Epoch 34/100\n",
      "50400/50400 [==============================] - 3s 52us/step - loss: 0.6677 - acc: 0.7495\n",
      "Epoch 35/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.6638 - acc: 0.7507\n",
      "Epoch 36/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.6641 - acc: 0.7508\n",
      "Epoch 37/100\n",
      "50400/50400 [==============================] - 3s 52us/step - loss: 0.6638 - acc: 0.7504\n",
      "Epoch 38/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.6589 - acc: 0.7529\n",
      "Epoch 39/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6587 - acc: 0.7522\n",
      "Epoch 40/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.6528 - acc: 0.7540\n",
      "Epoch 41/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.6548 - acc: 0.7549\n",
      "Epoch 42/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6550 - acc: 0.7551\n",
      "Epoch 43/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.6482 - acc: 0.7569\n",
      "Epoch 44/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6476 - acc: 0.7574\n",
      "Epoch 45/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.6447 - acc: 0.7584\n",
      "Epoch 46/100\n",
      "50400/50400 [==============================] - 3s 56us/step - loss: 0.6437 - acc: 0.7591\n",
      "Epoch 47/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.6415 - acc: 0.7597\n",
      "Epoch 48/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.6396 - acc: 0.7602\n",
      "Epoch 49/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.6448 - acc: 0.7578\n",
      "Epoch 50/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6433 - acc: 0.7601\n",
      "Epoch 51/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6331 - acc: 0.7633\n",
      "Epoch 52/100\n",
      "50400/50400 [==============================] - 3s 51us/step - loss: 0.6370 - acc: 0.7617\n",
      "Epoch 53/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6375 - acc: 0.7609\n",
      "Epoch 54/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6350 - acc: 0.7630\n",
      "Epoch 55/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6369 - acc: 0.7614\n",
      "Epoch 56/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6306 - acc: 0.7648\n",
      "Epoch 57/100\n",
      "50400/50400 [==============================] - 3s 52us/step - loss: 0.6333 - acc: 0.7613\n",
      "Epoch 58/100\n",
      "50400/50400 [==============================] - 3s 52us/step - loss: 0.6297 - acc: 0.7647\n",
      "Epoch 59/100\n",
      "50400/50400 [==============================] - 3s 53us/step - loss: 0.6317 - acc: 0.7631\n",
      "Epoch 60/100\n",
      "50400/50400 [==============================] - 3s 51us/step - loss: 0.6300 - acc: 0.7651\n",
      "Epoch 61/100\n",
      "50400/50400 [==============================] - 3s 51us/step - loss: 0.6274 - acc: 0.7644\n",
      "Epoch 62/100\n",
      "50400/50400 [==============================] - 3s 51us/step - loss: 0.6275 - acc: 0.7645\n",
      "Epoch 63/100\n",
      "50400/50400 [==============================] - 3s 51us/step - loss: 0.6235 - acc: 0.7666\n",
      "Epoch 64/100\n",
      "50400/50400 [==============================] - 3s 51us/step - loss: 0.6222 - acc: 0.7678\n",
      "Epoch 65/100\n",
      "50400/50400 [==============================] - 3s 52us/step - loss: 0.6228 - acc: 0.7688\n",
      "Epoch 66/100\n",
      "50400/50400 [==============================] - 3s 51us/step - loss: 0.6235 - acc: 0.7680\n",
      "Epoch 67/100\n",
      "50400/50400 [==============================] - 3s 51us/step - loss: 0.6173 - acc: 0.7689\n",
      "Epoch 68/100\n",
      "50400/50400 [==============================] - 3s 51us/step - loss: 0.6180 - acc: 0.7693\n",
      "Epoch 69/100\n",
      "50400/50400 [==============================] - 3s 50us/step - loss: 0.6169 - acc: 0.7696\n",
      "Epoch 70/100\n",
      "50400/50400 [==============================] - 3s 51us/step - loss: 0.6204 - acc: 0.7684\n",
      "Epoch 71/100\n",
      "50400/50400 [==============================] - 3s 56us/step - loss: 0.6160 - acc: 0.7702\n",
      "Epoch 72/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6133 - acc: 0.7711\n",
      "Epoch 73/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.6130 - acc: 0.7707\n",
      "Epoch 74/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6141 - acc: 0.7704\n",
      "Epoch 75/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6177 - acc: 0.7690\n",
      "Epoch 76/100\n",
      "50400/50400 [==============================] - 3s 57us/step - loss: 0.6129 - acc: 0.7722\n",
      "Epoch 77/100\n",
      "50400/50400 [==============================] - 3s 57us/step - loss: 0.6106 - acc: 0.7708\n",
      "Epoch 78/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.6099 - acc: 0.7730\n",
      "Epoch 79/100\n",
      "50400/50400 [==============================] - 3s 56us/step - loss: 0.6106 - acc: 0.7715\n",
      "Epoch 80/100\n",
      "50400/50400 [==============================] - 3s 58us/step - loss: 0.6074 - acc: 0.7735\n",
      "Epoch 81/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6080 - acc: 0.7723\n",
      "Epoch 82/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6062 - acc: 0.7736\n",
      "Epoch 83/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6073 - acc: 0.7723\n",
      "Epoch 84/100\n",
      "50400/50400 [==============================] - 3s 60us/step - loss: 0.6059 - acc: 0.7734\n",
      "Epoch 85/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.6060 - acc: 0.7747\n",
      "Epoch 86/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6032 - acc: 0.7756\n",
      "Epoch 87/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.6049 - acc: 0.7740\n",
      "Epoch 88/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6040 - acc: 0.7730\n",
      "Epoch 89/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6017 - acc: 0.7767\n",
      "Epoch 90/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.6030 - acc: 0.7751\n",
      "Epoch 91/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6008 - acc: 0.7745\n",
      "Epoch 92/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6033 - acc: 0.7735\n",
      "Epoch 93/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6038 - acc: 0.7743\n",
      "Epoch 94/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.5978 - acc: 0.7769\n",
      "Epoch 95/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.5998 - acc: 0.7760\n",
      "Epoch 96/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.6021 - acc: 0.7744\n",
      "Epoch 97/100\n",
      "50400/50400 [==============================] - 3s 54us/step - loss: 0.5944 - acc: 0.7780\n",
      "Epoch 98/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.5951 - acc: 0.7777\n",
      "Epoch 99/100\n",
      "50400/50400 [==============================] - 3s 55us/step - loss: 0.5975 - acc: 0.7782\n",
      "Epoch 100/100\n",
      "50400/50400 [==============================] - 3s 56us/step - loss: 0.5952 - acc: 0.7784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x285a0cc1e10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xhist, y, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 991  216   24  292  123  121   33]\n",
      " [  83 1421    5  227   11   40   13]\n",
      " [   5    0 1772    0    0    0   23]\n",
      " [  94  226    7 1395   52   16   10]\n",
      " [ 331   76   11  498  835   27   22]\n",
      " [  44   17    1    9    7 1722    0]\n",
      " [  50   16   72   32   40    0 1590]]\n",
      "0.7719047619047619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.62015019, 0.72058824, 0.93657505, 0.5686914 , 0.78183521,\n",
       "        0.894081  , 0.94027203]),\n",
       " array([0.55055556, 0.78944444, 0.98444444, 0.775     , 0.46388889,\n",
       "        0.95666667, 0.88333333]),\n",
       " array([0.58328428, 0.75344645, 0.95991333, 0.65600752, 0.58228731,\n",
       "        0.92431562, 0.91091378]),\n",
       " array([1800, 1800, 1800, 1800, 1800, 1800, 1800], dtype=int64))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def threeChannelHistogram(images, bins):\n",
    "    histograms = []\n",
    "    for image in images:\n",
    "        redHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        greenHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        blueHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        #print(np.hstack((redHist, greenHist, blueHist)))\n",
    "        histograms.append(np.hstack((redHist, greenHist, blueHist)))\n",
    "        #histograms.append(np.histogram(image, bins=bins, range=(0, 255))[0])\n",
    "    return np.stack(histograms)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "Xhisttest = threeChannelHistogram(Xtest, bins=bins)\n",
    "predict = model.predict(Xhisttest)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest.argmax(axis=1), predict.argmax(axis=1)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(ytest.argmax(axis=1), predict.argmax(axis=1)))\n",
    "precision_recall_fscore_support(ytest.argmax(axis=1), predict.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50400/50400 [==============================] - 3s 56us/step - loss: 2.2428 - acc: 0.1536\n",
      "Epoch 2/100\n",
      "50400/50400 [==============================] - 2s 46us/step - loss: 1.9383 - acc: 0.1471\n",
      "Epoch 3/100\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 1.9461 - acc: 0.1416\n",
      "Epoch 4/100\n",
      "50400/50400 [==============================] - 3s 50us/step - loss: 1.9470 - acc: 0.1413\n",
      "Epoch 5/100\n",
      "50400/50400 [==============================] - 2s 47us/step - loss: 1.9467 - acc: 0.1406\n",
      "Epoch 6/100\n",
      "50400/50400 [==============================] - 2s 46us/step - loss: 1.9467 - acc: 0.1415\n",
      "Epoch 7/100\n",
      "50400/50400 [==============================] - 2s 45us/step - loss: 1.9467 - acc: 0.1393\n",
      "Epoch 8/100\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 1.9467 - acc: 0.1424\n",
      "Epoch 9/100\n",
      "50400/50400 [==============================] - 2s 42us/step - loss: 1.9467 - acc: 0.1384\n",
      "Epoch 10/100\n",
      "50400/50400 [==============================] - ETA: 0s - loss: 1.9467 - acc: 0.140 - 2s 41us/step - loss: 1.9467 - acc: 0.1402\n",
      "Epoch 11/100\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 1.9467 - acc: 0.1397\n",
      "Epoch 12/100\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 1.9467 - acc: 0.1404\n",
      "Epoch 13/100\n",
      "50400/50400 [==============================] - 2s 42us/step - loss: 1.9467 - acc: 0.1389\n",
      "Epoch 14/100\n",
      "50400/50400 [==============================] - 2s 42us/step - loss: 1.9467 - acc: 0.1417\n",
      "Epoch 15/100\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 1.9467 - acc: 0.1422\n",
      "Epoch 16/100\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 1.9467 - acc: 0.1389\n",
      "Epoch 17/100\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 1.9467 - acc: 0.1415\n",
      "Epoch 18/100\n",
      "50400/50400 [==============================] - 2s 44us/step - loss: 1.9467 - acc: 0.1437\n",
      "Epoch 19/100\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 1.9467 - acc: 0.1405\n",
      "Epoch 20/100\n",
      "50400/50400 [==============================] - 2s 42us/step - loss: 1.9467 - acc: 0.1398\n",
      "Epoch 21/100\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 1.9467 - acc: 0.1418\n",
      "Epoch 22/100\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 1.9467 - acc: 0.1402\n",
      "Epoch 23/100\n",
      "50400/50400 [==============================] - 2s 44us/step - loss: 1.9467 - acc: 0.1404\n",
      "Epoch 24/100\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 1.9467 - acc: 0.1410\n",
      "Epoch 25/100\n",
      "50400/50400 [==============================] - 2s 44us/step - loss: 1.9467 - acc: 0.1390\n",
      "Epoch 26/100\n",
      "50400/50400 [==============================] - 2s 48us/step - loss: 1.9467 - acc: 0.1390\n",
      "Epoch 27/100\n",
      "50400/50400 [==============================] - 3s 50us/step - loss: 1.9467 - acc: 0.1401\n",
      "Epoch 28/100\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 1.9467 - acc: 0.1411\n",
      "Epoch 29/100\n",
      "50400/50400 [==============================] - 2s 44us/step - loss: 1.9467 - acc: 0.1394\n",
      "Epoch 30/100\n",
      "50400/50400 [==============================] - 2s 44us/step - loss: 1.9467 - acc: 0.1423\n",
      "Epoch 31/100\n",
      "50400/50400 [==============================] - 2s 44us/step - loss: 1.9467 - acc: 0.1387\n",
      "Epoch 32/100\n",
      "50400/50400 [==============================] - 2s 44us/step - loss: 1.9467 - acc: 0.1381\n",
      "Epoch 33/100\n",
      "50400/50400 [==============================] - 2s 44us/step - loss: 1.9467 - acc: 0.1399\n",
      "Epoch 34/100\n",
      "50400/50400 [==============================] - 2s 45us/step - loss: 1.9467 - acc: 0.1386\n",
      "Epoch 35/100\n",
      "50400/50400 [==============================] - 2s 44us/step - loss: 1.9467 - acc: 0.1408\n",
      "Epoch 36/100\n",
      "50400/50400 [==============================] - 2s 42us/step - loss: 1.9467 - acc: 0.1429\n",
      "Epoch 37/100\n",
      "50400/50400 [==============================] - 2s 44us/step - loss: 1.9467 - acc: 0.1418\n",
      "Epoch 38/100\n",
      "50400/50400 [==============================] - 2s 49us/step - loss: 1.9467 - acc: 0.1422\n",
      "Epoch 39/100\n",
      "50400/50400 [==============================] - 2s 46us/step - loss: 1.9467 - acc: 0.1390\n",
      "Epoch 40/100\n",
      "50400/50400 [==============================] - 2s 47us/step - loss: 1.9467 - acc: 0.1395\n",
      "Epoch 41/100\n",
      "50400/50400 [==============================] - 2s 41us/step - loss: 1.9467 - acc: 0.1403\n",
      "Epoch 42/100\n",
      "50400/50400 [==============================] - 2s 44us/step - loss: 1.9467 - acc: 0.1420\n",
      "Epoch 43/100\n",
      "50400/50400 [==============================] - 2s 42us/step - loss: 1.9467 - acc: 0.1386\n",
      "Epoch 44/100\n",
      "50400/50400 [==============================] - 2s 47us/step - loss: 1.9467 - acc: 0.1401\n",
      "Epoch 45/100\n",
      "50400/50400 [==============================] - 2s 47us/step - loss: 1.9467 - acc: 0.1405\n",
      "Epoch 46/100\n",
      "50400/50400 [==============================] - 2s 45us/step - loss: 1.9467 - acc: 0.1406\n",
      "Epoch 47/100\n",
      "24192/50400 [=============>................] - ETA: 1s - loss: 1.9458 - acc: 0.1438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-107721cbee38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Compile model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXhist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1202\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1204\u001b[1;33m                             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1205\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                         raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=bins * 3, activation='relu'))\n",
    "model.add(Dense(32, input_dim=bins * 3, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(categories, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(Xhist, y, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 998  148   25  161  316  101   51]\n",
      " [ 165 1249    6  289   33   40   18]\n",
      " [   3    0 1772    0    0    0   25]\n",
      " [ 112  194    8 1149  274   45   18]\n",
      " [ 213   28   12  220 1251   46   30]\n",
      " [  61   20    2    9   16 1691    1]\n",
      " [  20    4   51   10   42    0 1673]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = ['unfiltered', 'clarendon', 'gingham', 'juno', 'lark', 'gotham', 'reyes']\n",
    "cm = confusion_matrix(ytest.argmax(axis=1), predict.argmax(axis=1))\n",
    "print(cm)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('NNFilterClassifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a70009143d02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \"\"\"\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# pydot raises a generic Exception here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
