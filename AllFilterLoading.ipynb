{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from loadFilteredData import *\n",
    "#loading all data\n",
    "origImg = loadAllTopicData('original')\n",
    "gingham = loadAllTopicData('gingham')\n",
    "clarendon = loadAllTopicData('clarendon')\n",
    "juno = loadAllTopicData('juno')\n",
    "lark = loadAllTopicData('lark')\n",
    "gotham = loadAllTopicData('gotham')\n",
    "reyes = loadAllTopicData('reyes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "X, y, Xtest, ytest = createData([origImg, clarendon, gingham, juno, lark, gotham, reyes], .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50400, 128, 128, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threeChannelHistogram(images, bins):\n",
    "    histograms = []\n",
    "    for image in images:\n",
    "        redHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        greenHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        blueHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        #print(np.hstack((redHist, greenHist, blueHist)))\n",
    "        histograms.append(np.hstack((redHist, greenHist, blueHist)))\n",
    "        #histograms.append(np.histogram(image, bins=bins, range=(0, 255))[0])\n",
    "    return np.stack(histograms)\n",
    "bins = 255\n",
    "categories = 7\n",
    "Xhist = threeChannelHistogram(X, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=bins * 3, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(categories, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50400/50400 [==============================] - 2s 46us/step - loss: 0.3911 - acc: 0.8629\n",
      "Epoch 2/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.3391 - acc: 0.8720\n",
      "Epoch 3/50\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.3168 - acc: 0.8747\n",
      "Epoch 4/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.2900 - acc: 0.8824\n",
      "Epoch 5/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.2681 - acc: 0.8953\n",
      "Epoch 6/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.2551 - acc: 0.9020\n",
      "Epoch 7/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.2461 - acc: 0.9031\n",
      "Epoch 8/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.2377 - acc: 0.9036\n",
      "Epoch 9/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.2293 - acc: 0.9047\n",
      "Epoch 10/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.2233 - acc: 0.9056\n",
      "Epoch 11/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.2200 - acc: 0.9057\n",
      "Epoch 12/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.2194 - acc: 0.9054\n",
      "Epoch 13/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.2129 - acc: 0.9072\n",
      "Epoch 14/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.2089 - acc: 0.9106\n",
      "Epoch 15/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.2061 - acc: 0.9139\n",
      "Epoch 16/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.2038 - acc: 0.9151\n",
      "Epoch 17/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.2008 - acc: 0.9165\n",
      "Epoch 18/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1964 - acc: 0.9175\n",
      "Epoch 19/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.1961 - acc: 0.9178\n",
      "Epoch 20/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1932 - acc: 0.9192\n",
      "Epoch 21/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1914 - acc: 0.9197: 1\n",
      "Epoch 22/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1888 - acc: 0.9208\n",
      "Epoch 23/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1861 - acc: 0.9219\n",
      "Epoch 24/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1852 - acc: 0.9223\n",
      "Epoch 25/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1836 - acc: 0.9223\n",
      "Epoch 26/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.1814 - acc: 0.9231\n",
      "Epoch 27/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1828 - acc: 0.9227\n",
      "Epoch 28/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1797 - acc: 0.9239\n",
      "Epoch 29/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1771 - acc: 0.9244\n",
      "Epoch 30/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.1772 - acc: 0.9247\n",
      "Epoch 31/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1764 - acc: 0.9251\n",
      "Epoch 32/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1744 - acc: 0.9259\n",
      "Epoch 33/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.1730 - acc: 0.9267\n",
      "Epoch 34/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.1731 - acc: 0.9272\n",
      "Epoch 35/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1719 - acc: 0.9275\n",
      "Epoch 36/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1717 - acc: 0.9286\n",
      "Epoch 37/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1706 - acc: 0.9289\n",
      "Epoch 38/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1696 - acc: 0.9298\n",
      "Epoch 39/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1700 - acc: 0.9293\n",
      "Epoch 40/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.1685 - acc: 0.9300\n",
      "Epoch 41/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1675 - acc: 0.9305\n",
      "Epoch 42/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1669 - acc: 0.9309\n",
      "Epoch 43/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.1668 - acc: 0.9312\n",
      "Epoch 44/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.1661 - acc: 0.9315\n",
      "Epoch 45/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.1666 - acc: 0.9310\n",
      "Epoch 46/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1649 - acc: 0.9324\n",
      "Epoch 47/50\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.1651 - acc: 0.9321\n",
      "Epoch 48/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.1638 - acc: 0.9329\n",
      "Epoch 49/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.1634 - acc: 0.9328\n",
      "Epoch 50/50\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.1636 - acc: 0.9328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d3bfb9390>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xhist, y, epochs=50, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 974  146   20  197  299   90   74]\n",
      " [ 157 1242    4  311   32   29   25]\n",
      " [   2    0 1767    2    0    0   29]\n",
      " [ 144  186    5 1130  302    8   25]\n",
      " [ 280   22    9  311 1121   12   45]\n",
      " [  87   32    1    7    3 1670    0]\n",
      " [  10    0   60   19   28    0 1683]]\n",
      "0.7608730158730159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.58887545, 0.76289926, 0.94694534, 0.57157309, 0.6280112 ,\n",
       "        0.92316197, 0.89473684]),\n",
       " array([0.54111111, 0.69      , 0.98166667, 0.62777778, 0.62277778,\n",
       "        0.92777778, 0.935     ]),\n",
       " array([0.56398379, 0.72462077, 0.96399345, 0.59835849, 0.62538354,\n",
       "        0.92546412, 0.91442543]),\n",
       " array([1800, 1800, 1800, 1800, 1800, 1800, 1800], dtype=int64))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def threeChannelHistogram(images, bins):\n",
    "    histograms = []\n",
    "    for image in images:\n",
    "        redHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        greenHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        blueHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        #print(np.hstack((redHist, greenHist, blueHist)))\n",
    "        histograms.append(np.hstack((redHist, greenHist, blueHist)))\n",
    "        #histograms.append(np.histogram(image, bins=bins, range=(0, 255))[0])\n",
    "    return np.stack(histograms)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "Xhisttest = threeChannelHistogram(Xtest, bins=bins)\n",
    "predict = model.predict(Xhisttest)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest.argmax(axis=1), predict.argmax(axis=1)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(ytest.argmax(axis=1), predict.argmax(axis=1)))\n",
    "precision_recall_fscore_support(ytest.argmax(axis=1), predict.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
