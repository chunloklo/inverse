{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from loadFilteredData import *\n",
    "#loading all data\n",
    "origImg = loadAllTopicData('original')\n",
    "gingham = loadAllTopicData('gingham')\n",
    "clarendon = loadAllTopicData('clarendon')\n",
    "juno = loadAllTopicData('juno')\n",
    "lark = loadAllTopicData('lark')\n",
    "gotham = loadAllTopicData('gotham')\n",
    "reyes = loadAllTopicData('reyes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "def createDataPlaces(images, trainPercentage):\n",
    "    categories = len(images)\n",
    "\n",
    "    imgList = []\n",
    "    vectors = []\n",
    "\n",
    "    testImgList = []\n",
    "    testVectors = []\n",
    "\n",
    "\n",
    "    #data for original image\n",
    "    for c in range(categories):\n",
    "        numImages = images[c].shape[0]\n",
    "        print(numImages)\n",
    "        numTrain = int(numImages * trainPercentage)\n",
    "        imgList.append(images[c][:numTrain])\n",
    "\n",
    "        featureVector = np.zeros((numTrain, categories))\n",
    "        featureVector[:, c] = 1\n",
    "        vectors.append(featureVector)\n",
    "    \n",
    "        #testing data\n",
    "        testImgList.append(images[c][numTrain:])\n",
    "\n",
    "        featureVector = np.zeros((numImages - numTrain, categories))\n",
    "        featureVector[:, c] = 1\n",
    "        testVectors.append(featureVector)\n",
    "\n",
    "\n",
    "    X = np.vstack(imgList)\n",
    "    y = np.vstack(vectors)\n",
    "\n",
    "    Xtest = np.vstack(testImgList)\n",
    "    ytest = np.vstack(testVectors)\n",
    "\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "    Xtest, ytest = shuffle(Xtest, ytest, random_state=0)\n",
    "    return X, y, Xtest, ytest\n",
    "X, y, Xtest, ytest = createDataPlaces([origImg, clarendon, gingham, juno, lark, gotham, reyes], .9)\n",
    "# X, y, Xtest, ytest = createDataPlaces([origImg, juno], .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsmall = []\n",
    "ysmall = []\n",
    "for i in range(X.shape[0]):\n",
    "    l = 0\n",
    "    for j in range(0, X.shape[1], X.shape[1] // 4):\n",
    "        for k in range(0, X.shape[1], X.shape[1] // 4):\n",
    "            block = X[i, j : j + 32, k : k + 32]\n",
    "            Xsmall.append(block)\n",
    "            ysmall.append(y[i])\n",
    "            l += 1\n",
    "Xsmall = np.array(Xsmall)\n",
    "ysmall = np.array(ysmall)\n",
    "Xsmall, ysmall = shuffle(Xsmall, ysmall, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import LeakyReLU\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), strides=2))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Conv2D(32, (3, 3), strides = 2))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(MaxPooling2D(pool_size=3, strides =2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(256))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 902664 samples, validate on 4536 samples\n",
      "Epoch 1/150\n",
      "902664/902664 [==============================] - 90s 99us/step - loss: 0.8814 - acc: 0.6675 - val_loss: 0.7589 - val_acc: 0.7134\n",
      "Epoch 2/150\n",
      "902664/902664 [==============================] - 94s 104us/step - loss: 0.7225 - acc: 0.7276 - val_loss: 0.7137 - val_acc: 0.7209\n",
      "Epoch 3/150\n",
      "902664/902664 [==============================] - 90s 99us/step - loss: 0.6695 - acc: 0.7471 - val_loss: 0.6754 - val_acc: 0.7372\n",
      "Epoch 4/150\n",
      "902664/902664 [==============================] - 91s 101us/step - loss: 0.6394 - acc: 0.7584 - val_loss: 0.6958 - val_acc: 0.7447\n",
      "Epoch 5/150\n",
      "902664/902664 [==============================] - 90s 99us/step - loss: 0.6217 - acc: 0.7650 - val_loss: 0.8066 - val_acc: 0.6944\n",
      "Epoch 6/150\n",
      "902664/902664 [==============================] - 90s 100us/step - loss: 0.6066 - acc: 0.7706 - val_loss: 0.6851 - val_acc: 0.7317\n",
      "Epoch 7/150\n",
      "902664/902664 [==============================] - 88s 98us/step - loss: 0.5963 - acc: 0.7741 - val_loss: 0.8634 - val_acc: 0.6788\n",
      "Epoch 8/150\n",
      "902664/902664 [==============================] - 85s 94us/step - loss: 0.5863 - acc: 0.7780 - val_loss: 0.9188 - val_acc: 0.6711\n",
      "Epoch 9/150\n",
      "902664/902664 [==============================] - 89s 99us/step - loss: 0.5781 - acc: 0.7814 - val_loss: 0.6254 - val_acc: 0.7623\n",
      "Epoch 10/150\n",
      "902664/902664 [==============================] - 91s 100us/step - loss: 0.5710 - acc: 0.7835 - val_loss: 0.7067 - val_acc: 0.7392\n",
      "Epoch 11/150\n",
      "902664/902664 [==============================] - 91s 101us/step - loss: 0.5657 - acc: 0.7856 - val_loss: 0.7169 - val_acc: 0.7257\n",
      "Epoch 12/150\n",
      "902664/902664 [==============================] - 90s 100us/step - loss: 0.5592 - acc: 0.7885 - val_loss: 0.6169 - val_acc: 0.7668\n",
      "Epoch 13/150\n",
      "902664/902664 [==============================] - 91s 101us/step - loss: 0.5544 - acc: 0.7899 - val_loss: 0.5944 - val_acc: 0.7707\n",
      "Epoch 14/150\n",
      "902664/902664 [==============================] - 93s 103us/step - loss: 0.5493 - acc: 0.7919 - val_loss: 0.6779 - val_acc: 0.7377\n",
      "Epoch 15/150\n",
      "902664/902664 [==============================] - 91s 101us/step - loss: 0.5444 - acc: 0.7935 - val_loss: 0.5826 - val_acc: 0.7731\n",
      "Epoch 16/150\n",
      "902664/902664 [==============================] - 89s 99us/step - loss: 0.5386 - acc: 0.7957 - val_loss: 0.5911 - val_acc: 0.7802\n",
      "Epoch 17/150\n",
      "902664/902664 [==============================] - 91s 101us/step - loss: 0.5353 - acc: 0.7963 - val_loss: 0.5757 - val_acc: 0.7791\n",
      "Epoch 18/150\n",
      "902664/902664 [==============================] - 89s 98us/step - loss: 0.5307 - acc: 0.7981 - val_loss: 0.5831 - val_acc: 0.7758\n",
      "Epoch 19/150\n",
      "902664/902664 [==============================] - 89s 99us/step - loss: 0.5283 - acc: 0.7991 - val_loss: 0.6253 - val_acc: 0.7754\n",
      "Epoch 20/150\n",
      "902664/902664 [==============================] - 85s 94us/step - loss: 0.5241 - acc: 0.8003 - val_loss: 0.6337 - val_acc: 0.7646\n",
      "Epoch 21/150\n",
      "902664/902664 [==============================] - 85s 94us/step - loss: 0.5229 - acc: 0.8010 - val_loss: 0.5398 - val_acc: 0.7910\n",
      "Epoch 22/150\n",
      "416512/902664 [============>.................] - ETA: 45s - loss: 0.5149 - acc: 0.8043"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-4a93b1280186>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXsmall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mysmall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2332\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2333\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(Xsmall, ysmall, epochs=150, batch_size=128, validation_split=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
