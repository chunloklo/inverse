{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from loadFilteredData import *\n",
    "#loading all data\n",
    "origImg = loadAllTopicData('original')\n",
    "gingham = loadAllTopicData('gingham')\n",
    "clarendon = loadAllTopicData('clarendon')\n",
    "juno = loadAllTopicData('juno')\n",
    "lark = loadAllTopicData('lark')\n",
    "gotham = loadAllTopicData('gotham')\n",
    "reyes = loadAllTopicData('reyes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "def createDataPlaces(images, trainPercentage, validationPercentage):\n",
    "    categories = len(images)\n",
    "\n",
    "    imgList = []\n",
    "    vectors = []\n",
    "\n",
    "    testImgList = []\n",
    "    testVectors = []\n",
    "\n",
    "    valImgList = []\n",
    "    valVectors = []\n",
    "    \n",
    "\n",
    "    #data for original image\n",
    "    for c in range(categories):\n",
    "        numImages = images[c].shape[0]\n",
    "        print(numImages)\n",
    "        numTrain = int(numImages * trainPercentage)\n",
    "        numVal = int(numTrain * validationPercentage)\n",
    "        \n",
    "        imgList.append(images[c][:numTrain - numVal])\n",
    "        \n",
    "        valImgList.append(images[c][numTrain - numVal:numTrain])\n",
    "\n",
    "        featureVector = np.zeros((numTrain - numVal, categories))\n",
    "        featureVector[:, c] = 1\n",
    "        vectors.append(featureVector)\n",
    "        \n",
    "        featureVector = np.zeros((numVal, categories))\n",
    "        featureVector[:, c] = 1\n",
    "        valVectors.append(featureVector)\n",
    "    \n",
    "        #testing data\n",
    "        testImgList.append(images[c][numTrain:])\n",
    "\n",
    "        featureVector = np.zeros((numImages - numTrain, categories))\n",
    "        featureVector[:, c] = 1\n",
    "        testVectors.append(featureVector)\n",
    "\n",
    "\n",
    "    X = np.vstack(imgList)\n",
    "    y = np.vstack(vectors)\n",
    "\n",
    "    Xtest = np.vstack(testImgList)\n",
    "    ytest = np.vstack(testVectors)\n",
    "    \n",
    "    Xval = np.vstack(valImgList)\n",
    "    yval = np.vstack(valVectors)\n",
    "\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "    Xtest, ytest = shuffle(Xtest, ytest, random_state=0)\n",
    "    Xval, yval = shuffle(Xval, yval, random_state=0)\n",
    "    \n",
    "    return X, y, Xtest, ytest, Xval, yval\n",
    "X, y, Xtest, ytest, Xval, yval = createDataPlaces([origImg, clarendon, gingham, juno, lark, gotham, reyes], .9, .005)\n",
    "# X, y, Xtest, ytest, Xval, yval = createDataPlaces([origImg, juno], .9, .005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56420, 128, 128, 3) (56420, 7)\n",
      "(6300, 128, 128, 3) (6300, 7)\n",
      "(280, 128, 128, 3) (280, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "print(Xtest.shape, ytest.shape)\n",
    "print(Xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitImg(X, y):\n",
    "    Xsmall = []\n",
    "    ysmall = []\n",
    "    for i in range(X.shape[0]):\n",
    "        l = 0\n",
    "        for j in range(0, X.shape[1], X.shape[1] // 4):\n",
    "            for k in range(0, X.shape[1], X.shape[1] // 4):\n",
    "                block = X[i, j : j + 32, k : k + 32]\n",
    "                Xsmall.append(block)\n",
    "                ysmall.append(y[i])\n",
    "                l += 1\n",
    "    Xsmall = np.array(Xsmall)\n",
    "    ysmall = np.array(ysmall)\n",
    "    return Xsmall, ysmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsmall, ysmall = splitImg(X, y)\n",
    "Xval_small, yval_small = splitImg(Xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(902720, 32, 32, 3) (902720, 7)\n",
      "(4480, 32, 32, 3) (4480, 7)\n"
     ]
    }
   ],
   "source": [
    "print(Xsmall.shape, ysmall.shape)\n",
    "print(Xval_small.shape, yval_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import LeakyReLU\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), strides=2))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Conv2D(32, (3, 3), strides = 2))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(MaxPooling2D(pool_size=3, strides =2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(256))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 902720 samples, validate on 4480 samples\n",
      "Epoch 1/5\n",
      "902720/902720 [==============================] - 46s 50us/step - loss: 0.3736 - acc: 0.8555 - val_loss: 0.4064 - val_acc: 0.8391\n",
      "Epoch 2/5\n",
      "902720/902720 [==============================] - 45s 50us/step - loss: 0.3853 - acc: 0.8518 - val_loss: 0.3745 - val_acc: 0.8500\n",
      "Epoch 3/5\n",
      "902720/902720 [==============================] - 46s 51us/step - loss: 0.3693 - acc: 0.8573 - val_loss: 0.3827 - val_acc: 0.8484\n",
      "Epoch 4/5\n",
      "902720/902720 [==============================] - 47s 52us/step - loss: 0.3759 - acc: 0.8545 - val_loss: 0.3990 - val_acc: 0.8424\n",
      "Epoch 5/5\n",
      "902720/902720 [==============================] - 46s 51us/step - loss: 0.3658 - acc: 0.8582 - val_loss: 0.3927 - val_acc: 0.8433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cb8f760c88>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xsmall, ysmall, epochs=5, batch_size=4096, validation_data=(Xval_small, yval_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_small, ytest_small = splitImg(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12206   592   295   187   280   360   480]\n",
      " [ 1565 11127    76   123   180   888   441]\n",
      " [   31     7 14158     7     9    44   144]\n",
      " [  141    46   105 11470  2252   132   254]\n",
      " [  279    77   112  3777  9730    74   351]\n",
      " [  230   383    98   158    52 13401    78]\n",
      " [  426   101   499    70   142    56 13106]]\n",
      "0.845218253968254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.82040597, 0.90221357, 0.92276608, 0.72631712, 0.7694741 ,\n",
       "        0.89608826, 0.88232126]),\n",
       " array([0.84763889, 0.77270833, 0.98319444, 0.79652778, 0.67569444,\n",
       "        0.930625  , 0.91013889]),\n",
       " array([0.83380012, 0.83245427, 0.95202232, 0.75980392, 0.7195415 ,\n",
       "        0.91303015, 0.89601422]),\n",
       " array([14400, 14400, 14400, 14400, 14400, 14400, 14400], dtype=int64))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict(Xtest_small)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest_small.argmax(axis=1), predict.argmax(axis=1)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(ytest_small.argmax(axis=1), predict.argmax(axis=1)))\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(ytest_small.argmax(axis=1), predict.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100800, 7)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "predictOrig = []\n",
    "print(predict.shape)\n",
    "for i in range(0, predict.shape[0], 16):\n",
    "    votes = np.argmax(predict[i: i+16], axis=1)\n",
    "    vote = mode(votes)\n",
    "    predictOrig.append(vote[0])\n",
    "predictOrig = np.array(predictOrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300, 7)\n",
      "(6300, 1)\n"
     ]
    }
   ],
   "source": [
    "print(ytest.shape)\n",
    "print(predictOrig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chunlok Lo\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "predictVote = onehot_encoder.fit_transform(predictOrig)\n",
    "print(predictVote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[877   3   8   1   5   1   5]\n",
      " [ 24 858   1   0   1  11   5]\n",
      " [  1   0 899   0   0   0   0]\n",
      " [  0   0   3 867  29   0   1]\n",
      " [  2   0   4 181 711   1   1]\n",
      " [  0   0   0   2   0 898   0]\n",
      " [  0   0   8   0   0   0 892]]\n",
      "0.9526984126984127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.97013274, 0.99651568, 0.97399783, 0.82492864, 0.95308311,\n",
       "        0.98572997, 0.98672566]),\n",
       " array([0.97444444, 0.95333333, 0.99888889, 0.96333333, 0.79      ,\n",
       "        0.99777778, 0.99111111]),\n",
       " array([0.97228381, 0.97444634, 0.98628634, 0.88877499, 0.86391252,\n",
       "        0.99171728, 0.98891353]),\n",
       " array([900, 900, 900, 900, 900, 900, 900], dtype=int64))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest.argmax(axis=1), predictVote.argmax(axis=1)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(ytest.argmax(axis=1), predictVote.argmax(axis=1)))\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(ytest.argmax(axis=1), predictVote.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('FullNNFilter4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
