{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n",
      "['abbey', 'airport_terminal', 'amphitheater', 'amusement_park', 'aquarium', 'aqueduct', 'art_gallery', 'assembly_line', 'auditorium']\n",
      "Loading Topic: abbey\n",
      "Loading Topic: airport_terminal\n",
      "Loading Topic: amphitheater\n",
      "Loading Topic: amusement_park\n",
      "Loading Topic: aquarium\n",
      "Loading Topic: aqueduct\n",
      "Loading Topic: art_gallery\n",
      "Loading Topic: assembly_line\n",
      "Loading Topic: auditorium\n",
      "(9000, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from loadFilteredData import *\n",
    "#loading all data\n",
    "origImg = loadAllTopicData('original')\n",
    "gingham = loadAllTopicData('gingham')\n",
    "clarendon = loadAllTopicData('clarendon')\n",
    "juno = loadAllTopicData('juno')\n",
    "lark = loadAllTopicData('lark')\n",
    "gotham = loadAllTopicData('gotham')\n",
    "reyes = loadAllTopicData('reyes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chunlok Lo\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9000, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placeLabels = []\n",
    "for i in range(9):\n",
    "    for j in range(1000):\n",
    "        placeLabels.append([i])\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "placeLabels = enc.fit_transform(placeLabels)\n",
    "placeLabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "def createDataPlaces(images, places, trainPercentage):\n",
    "    categories = len(images)\n",
    "\n",
    "    imgList = []\n",
    "    vectors = []\n",
    "    trainPlaces = []\n",
    "\n",
    "    testImgList = []\n",
    "    testVectors = []\n",
    "    testPlaces = []\n",
    "\n",
    "\n",
    "    #data for original image\n",
    "    for c in range(categories):\n",
    "        numImages = images[c].shape[0]\n",
    "        print(numImages)\n",
    "        numTrain = int(numImages * trainPercentage)\n",
    "        imgList.append(images[c][:numTrain])\n",
    "\n",
    "        featureVector = np.zeros((numTrain, categories))\n",
    "        featureVector[:, c] = 1\n",
    "        vectors.append(featureVector)\n",
    "        \n",
    "        trainPlaces.append(places[:numTrain])\n",
    "\n",
    "        #testing data\n",
    "        testImgList.append(images[c][numTrain:])\n",
    "\n",
    "        featureVector = np.zeros((numImages - numTrain, categories))\n",
    "        featureVector[:, c] = 1\n",
    "        testVectors.append(featureVector)\n",
    "        \n",
    "        testPlaces.append(places[numTrain:])\n",
    "\n",
    "\n",
    "    X = np.vstack(imgList)\n",
    "    y = np.vstack(vectors)\n",
    "\n",
    "    Xtest = np.vstack(testImgList)\n",
    "    ytest = np.vstack(testVectors)\n",
    "    \n",
    "    trainPlaces = np.vstack(trainPlaces)\n",
    "    testPlaces = np.vstack(testPlaces)\n",
    "    \n",
    "\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "    Xtest, ytest = shuffle(Xtest, ytest, random_state=0)\n",
    "    return X, y, Xtest, ytest, trainPlaces, testPlaces\n",
    "X, y, Xtest, ytest, trainPlaces, testPlaces = createDataPlaces([origImg, clarendon, gingham, juno, lark, gotham, reyes], placeLabels, .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threeChannelHistogram(images, bins):\n",
    "    histograms = []\n",
    "    for image in images:\n",
    "        redHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        greenHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        blueHist = np.histogram(image[:, :, 0], bins=bins, range=(0, 255))[0]\n",
    "        #print(np.hstack((redHist, greenHist, blueHist)))\n",
    "        histograms.append(np.hstack((redHist, greenHist, blueHist)))\n",
    "        #histograms.append(np.histogram(image, bins=bins, range=(0, 255))[0])\n",
    "    return np.stack(histograms)\n",
    "bins = 250\n",
    "categories = 7\n",
    "Xhist = threeChannelHistogram(X, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50400, 750)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xhist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Xhist.npy', Xhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_hist = threeChannelHistogram(Xtest, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Xhist_test.npy', Xtest_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "XhistPlace = np.hstack((Xhist, trainPlaces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50400, 759)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XhistPlace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('XhistPlace.npy', XhistPlace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=bins * 3 + 9, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(categories, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 2.1594 - acc: 0.1492\n",
      "Epoch 2/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 1.9069 - acc: 0.1842\n",
      "Epoch 3/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 1.8602 - acc: 0.2043\n",
      "Epoch 4/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 1.7668 - acc: 0.2476\n",
      "Epoch 5/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 1.6482 - acc: 0.2839\n",
      "Epoch 6/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 1.5573 - acc: 0.3119\n",
      "Epoch 7/150\n",
      "50400/50400 [==============================] - 2s 30us/step - loss: 1.4948 - acc: 0.3513\n",
      "Epoch 8/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 1.4055 - acc: 0.3883\n",
      "Epoch 9/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 1.3645 - acc: 0.4031\n",
      "Epoch 10/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 1.3379 - acc: 0.4090\n",
      "Epoch 11/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 1.3120 - acc: 0.4312\n",
      "Epoch 12/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 1.2029 - acc: 0.5119\n",
      "Epoch 13/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 1.1164 - acc: 0.5460\n",
      "Epoch 14/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 1.0397 - acc: 0.5828\n",
      "Epoch 15/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.9850 - acc: 0.6067\n",
      "Epoch 16/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.9373 - acc: 0.6243\n",
      "Epoch 17/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.9125 - acc: 0.6355\n",
      "Epoch 18/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.8917 - acc: 0.6466\n",
      "Epoch 19/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.8756 - acc: 0.6497\n",
      "Epoch 20/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.8545 - acc: 0.6640\n",
      "Epoch 21/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.8387 - acc: 0.6731\n",
      "Epoch 22/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.8246 - acc: 0.6802\n",
      "Epoch 23/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.8205 - acc: 0.6849\n",
      "Epoch 24/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.8009 - acc: 0.6950\n",
      "Epoch 25/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.8018 - acc: 0.6927\n",
      "Epoch 26/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.7914 - acc: 0.6995\n",
      "Epoch 27/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.7894 - acc: 0.7026\n",
      "Epoch 28/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.7802 - acc: 0.7063\n",
      "Epoch 29/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.7766 - acc: 0.7060\n",
      "Epoch 30/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.7641 - acc: 0.7146\n",
      "Epoch 31/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.7607 - acc: 0.7167\n",
      "Epoch 32/150\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.7601 - acc: 0.7122\n",
      "Epoch 33/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.7518 - acc: 0.7203\n",
      "Epoch 34/150\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.7433 - acc: 0.7226\n",
      "Epoch 35/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.7368 - acc: 0.7258\n",
      "Epoch 36/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.7339 - acc: 0.7265\n",
      "Epoch 37/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.7335 - acc: 0.7274: 1s\n",
      "Epoch 38/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.7304 - acc: 0.7293\n",
      "Epoch 39/150\n",
      "50400/50400 [==============================] - 2s 30us/step - loss: 0.7281 - acc: 0.7307\n",
      "Epoch 40/150\n",
      "50400/50400 [==============================] - 2s 30us/step - loss: 0.7207 - acc: 0.7321\n",
      "Epoch 41/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.7221 - acc: 0.7311\n",
      "Epoch 42/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.7114 - acc: 0.7353\n",
      "Epoch 43/150\n",
      "50400/50400 [==============================] - 2s 30us/step - loss: 0.7133 - acc: 0.7364\n",
      "Epoch 44/150\n",
      "50400/50400 [==============================] - 2s 30us/step - loss: 0.7084 - acc: 0.7386\n",
      "Epoch 45/150\n",
      "50400/50400 [==============================] - 2s 30us/step - loss: 0.7096 - acc: 0.7377\n",
      "Epoch 46/150\n",
      "50400/50400 [==============================] - 2s 30us/step - loss: 0.7034 - acc: 0.7415\n",
      "Epoch 47/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.7029 - acc: 0.7413\n",
      "Epoch 48/150\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.6918 - acc: 0.7437\n",
      "Epoch 49/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.6890 - acc: 0.7454\n",
      "Epoch 50/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.6879 - acc: 0.7467\n",
      "Epoch 51/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.6795 - acc: 0.7491\n",
      "Epoch 52/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.6687 - acc: 0.7523\n",
      "Epoch 53/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.6607 - acc: 0.7552\n",
      "Epoch 54/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.6510 - acc: 0.7594\n",
      "Epoch 55/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.6468 - acc: 0.7617\n",
      "Epoch 56/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.6361 - acc: 0.7644\n",
      "Epoch 57/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.6305 - acc: 0.7660\n",
      "Epoch 58/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.6279 - acc: 0.7642\n",
      "Epoch 59/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.6204 - acc: 0.7690\n",
      "Epoch 60/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.6194 - acc: 0.7687\n",
      "Epoch 61/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.6118 - acc: 0.7706\n",
      "Epoch 62/150\n",
      "50400/50400 [==============================] - 2s 30us/step - loss: 0.6100 - acc: 0.7732\n",
      "Epoch 63/150\n",
      "50400/50400 [==============================] - 2s 30us/step - loss: 0.6101 - acc: 0.7738\n",
      "Epoch 64/150\n",
      "50400/50400 [==============================] - 2s 30us/step - loss: 0.6039 - acc: 0.7753\n",
      "Epoch 65/150\n",
      "50400/50400 [==============================] - 1s 30us/step - loss: 0.6065 - acc: 0.7735\n",
      "Epoch 66/150\n",
      "50400/50400 [==============================] - 2s 30us/step - loss: 0.5981 - acc: 0.7751\n",
      "Epoch 67/150\n",
      "50400/50400 [==============================] - 2s 30us/step - loss: 0.6006 - acc: 0.7741\n",
      "Epoch 68/150\n",
      "50400/50400 [==============================] - 2s 30us/step - loss: 0.5905 - acc: 0.7786\n",
      "Epoch 69/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.5949 - acc: 0.7780\n",
      "Epoch 70/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.5860 - acc: 0.7803\n",
      "Epoch 71/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5885 - acc: 0.7794\n",
      "Epoch 72/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.5778 - acc: 0.7839\n",
      "Epoch 73/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.5834 - acc: 0.7813\n",
      "Epoch 74/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.5768 - acc: 0.7843\n",
      "Epoch 75/150\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.5728 - acc: 0.7867\n",
      "Epoch 76/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5684 - acc: 0.7873\n",
      "Epoch 77/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.5679 - acc: 0.7887\n",
      "Epoch 78/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.5674 - acc: 0.7892\n",
      "Epoch 79/150\n",
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.5696 - acc: 0.7868\n",
      "Epoch 80/150\n",
      "50400/50400 [==============================] - 2s 32us/step - loss: 0.5620 - acc: 0.7894\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50400/50400 [==============================] - 2s 31us/step - loss: 0.5651 - acc: 0.7894\n",
      "Epoch 82/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5642 - acc: 0.7897\n",
      "Epoch 83/150\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.5582 - acc: 0.7908: 0s - loss: 0.5579 - acc:\n",
      "Epoch 84/150\n",
      "50400/50400 [==============================] - 2s 41us/step - loss: 0.5575 - acc: 0.7908\n",
      "Epoch 85/150\n",
      "50400/50400 [==============================] - 2s 37us/step - loss: 0.5513 - acc: 0.7947\n",
      "Epoch 86/150\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.5543 - acc: 0.7927\n",
      "Epoch 87/150\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.5498 - acc: 0.7942\n",
      "Epoch 88/150\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.5496 - acc: 0.7938\n",
      "Epoch 89/150\n",
      "50400/50400 [==============================] - 2s 39us/step - loss: 0.5481 - acc: 0.7970: 0s - loss: 0.541\n",
      "Epoch 90/150\n",
      "50400/50400 [==============================] - 2s 39us/step - loss: 0.5452 - acc: 0.7962\n",
      "Epoch 91/150\n",
      "50400/50400 [==============================] - 2s 37us/step - loss: 0.5461 - acc: 0.7940\n",
      "Epoch 92/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5454 - acc: 0.7971\n",
      "Epoch 93/150\n",
      "50400/50400 [==============================] - 2s 38us/step - loss: 0.5386 - acc: 0.7983\n",
      "Epoch 94/150\n",
      "50400/50400 [==============================] - 2s 37us/step - loss: 0.5391 - acc: 0.8001\n",
      "Epoch 95/150\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.5409 - acc: 0.7982\n",
      "Epoch 96/150\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.5352 - acc: 0.7994\n",
      "Epoch 97/150\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.5411 - acc: 0.7987\n",
      "Epoch 98/150\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.5292 - acc: 0.8022\n",
      "Epoch 99/150\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.5351 - acc: 0.8011\n",
      "Epoch 100/150\n",
      "50400/50400 [==============================] - 2s 37us/step - loss: 0.5357 - acc: 0.7993\n",
      "Epoch 101/150\n",
      "50400/50400 [==============================] - 2s 36us/step - loss: 0.5288 - acc: 0.8037\n",
      "Epoch 102/150\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.5287 - acc: 0.8017\n",
      "Epoch 103/150\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.5271 - acc: 0.8032\n",
      "Epoch 104/150\n",
      "50400/50400 [==============================] - 2s 35us/step - loss: 0.5300 - acc: 0.8029\n",
      "Epoch 105/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5271 - acc: 0.8043\n",
      "Epoch 106/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5299 - acc: 0.8029\n",
      "Epoch 107/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5277 - acc: 0.8039\n",
      "Epoch 108/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5221 - acc: 0.8056\n",
      "Epoch 109/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5171 - acc: 0.8083\n",
      "Epoch 110/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5241 - acc: 0.8049\n",
      "Epoch 111/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5196 - acc: 0.8047\n",
      "Epoch 112/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5198 - acc: 0.8058\n",
      "Epoch 113/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5167 - acc: 0.8069\n",
      "Epoch 114/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5279 - acc: 0.8040\n",
      "Epoch 115/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5157 - acc: 0.8085\n",
      "Epoch 116/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5148 - acc: 0.8082\n",
      "Epoch 117/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5230 - acc: 0.8060\n",
      "Epoch 118/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5131 - acc: 0.8094\n",
      "Epoch 119/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5096 - acc: 0.8107\n",
      "Epoch 120/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5158 - acc: 0.8085\n",
      "Epoch 121/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5085 - acc: 0.8128\n",
      "Epoch 122/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5114 - acc: 0.8116\n",
      "Epoch 123/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5056 - acc: 0.8132\n",
      "Epoch 124/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5087 - acc: 0.8113\n",
      "Epoch 125/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5273 - acc: 0.8050\n",
      "Epoch 126/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5125 - acc: 0.8079\n",
      "Epoch 127/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5103 - acc: 0.8105\n",
      "Epoch 128/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5057 - acc: 0.8130\n",
      "Epoch 129/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5016 - acc: 0.8146\n",
      "Epoch 130/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.5024 - acc: 0.8128: 1s \n",
      "Epoch 131/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.4998 - acc: 0.8145\n",
      "Epoch 132/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5005 - acc: 0.8145\n",
      "Epoch 133/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.4984 - acc: 0.8155\n",
      "Epoch 134/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.4967 - acc: 0.8153: 1s - loss: 0\n",
      "Epoch 135/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.4972 - acc: 0.8160\n",
      "Epoch 136/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.4984 - acc: 0.8146\n",
      "Epoch 137/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.4929 - acc: 0.8177\n",
      "Epoch 138/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.4928 - acc: 0.8173\n",
      "Epoch 139/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.4923 - acc: 0.8179\n",
      "Epoch 140/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.4985 - acc: 0.8167\n",
      "Epoch 141/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.4969 - acc: 0.8159\n",
      "Epoch 142/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.4921 - acc: 0.8167\n",
      "Epoch 143/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.4944 - acc: 0.8161\n",
      "Epoch 144/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.4915 - acc: 0.8187\n",
      "Epoch 145/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.5044 - acc: 0.8146\n",
      "Epoch 146/150\n",
      "50400/50400 [==============================] - 2s 33us/step - loss: 0.4895 - acc: 0.8188\n",
      "Epoch 147/150\n",
      "50400/50400 [==============================] - 2s 34us/step - loss: 0.4912 - acc: 0.8176\n",
      "Epoch 148/150\n",
      "50400/50400 [==============================] - 2s 40us/step - loss: 0.4875 - acc: 0.8192\n",
      "Epoch 149/150\n",
      "50400/50400 [==============================] - 2s 39us/step - loss: 0.4813 - acc: 0.8226\n",
      "Epoch 150/150\n",
      "50400/50400 [==============================] - 2s 43us/step - loss: 0.4881 - acc: 0.8192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fa69635da0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(XhistPlace, y, epochs=150, batch_size=256, validation_split=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49896 samples, validate on 504 samples\n",
      "Epoch 1/150\n",
      "49896/49896 [==============================] - 2s 46us/step - loss: 2.0091 - acc: 0.2287 - val_loss: 1.7518 - val_acc: 0.2381\n",
      "Epoch 2/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 1.7543 - acc: 0.2545 - val_loss: 1.7046 - val_acc: 0.2520\n",
      "Epoch 3/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 1.7169 - acc: 0.2625 - val_loss: 1.6987 - val_acc: 0.2341\n",
      "Epoch 4/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 1.6617 - acc: 0.2953 - val_loss: 1.5257 - val_acc: 0.3571\n",
      "Epoch 5/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 1.4899 - acc: 0.4234 - val_loss: 1.3739 - val_acc: 0.4504\n",
      "Epoch 6/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 1.2970 - acc: 0.4683 - val_loss: 1.2223 - val_acc: 0.4067\n",
      "Epoch 7/150\n",
      "49896/49896 [==============================] - 2s 32us/step - loss: 1.2120 - acc: 0.4644 - val_loss: 1.1818 - val_acc: 0.5655\n",
      "Epoch 8/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 1.1777 - acc: 0.5092 - val_loss: 1.1896 - val_acc: 0.5734\n",
      "Epoch 9/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 1.1465 - acc: 0.5383 - val_loss: 1.1791 - val_acc: 0.5714\n",
      "Epoch 10/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 1.1042 - acc: 0.5696 - val_loss: 1.0784 - val_acc: 0.5813\n",
      "Epoch 11/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 1.0419 - acc: 0.5966 - val_loss: 1.0874 - val_acc: 0.6052\n",
      "Epoch 12/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.9665 - acc: 0.6164 - val_loss: 0.9479 - val_acc: 0.6310\n",
      "Epoch 13/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.9026 - acc: 0.6513 - val_loss: 0.9242 - val_acc: 0.6687\n",
      "Epoch 14/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.8799 - acc: 0.6630 - val_loss: 0.9465 - val_acc: 0.6647\n",
      "Epoch 15/150\n",
      "49896/49896 [==============================] - 2s 32us/step - loss: 0.8518 - acc: 0.6779 - val_loss: 0.8445 - val_acc: 0.7024\n",
      "Epoch 16/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.8243 - acc: 0.6891 - val_loss: 0.8333 - val_acc: 0.6845\n",
      "Epoch 17/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.8232 - acc: 0.6898 - val_loss: 0.8809 - val_acc: 0.6806\n",
      "Epoch 18/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.8037 - acc: 0.6996 - val_loss: 0.8680 - val_acc: 0.7004\n",
      "Epoch 19/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.7792 - acc: 0.7097 - val_loss: 0.8401 - val_acc: 0.6944\n",
      "Epoch 20/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.7777 - acc: 0.7092 - val_loss: 0.8160 - val_acc: 0.7004\n",
      "Epoch 21/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.7586 - acc: 0.7169 - val_loss: 0.8216 - val_acc: 0.7202\n",
      "Epoch 22/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.7495 - acc: 0.7211 - val_loss: 0.7992 - val_acc: 0.7083\n",
      "Epoch 23/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.7518 - acc: 0.7181 - val_loss: 0.7800 - val_acc: 0.7361\n",
      "Epoch 24/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.7245 - acc: 0.7290 - val_loss: 0.8081 - val_acc: 0.7083\n",
      "Epoch 25/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.7211 - acc: 0.7300 - val_loss: 0.8368 - val_acc: 0.7242\n",
      "Epoch 26/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.7070 - acc: 0.7386 - val_loss: 0.8362 - val_acc: 0.7242\n",
      "Epoch 27/150\n",
      "49896/49896 [==============================] - 2s 37us/step - loss: 0.7031 - acc: 0.7377 - val_loss: 0.7803 - val_acc: 0.7401\n",
      "Epoch 28/150\n",
      "49896/49896 [==============================] - 2s 41us/step - loss: 0.6949 - acc: 0.7433 - val_loss: 0.7727 - val_acc: 0.7183\n",
      "Epoch 29/150\n",
      "49896/49896 [==============================] - 2s 41us/step - loss: 0.6896 - acc: 0.7433 - val_loss: 0.8325 - val_acc: 0.7044\n",
      "Epoch 30/150\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.6776 - acc: 0.7486 - val_loss: 0.8263 - val_acc: 0.7163\n",
      "Epoch 31/150\n",
      "49896/49896 [==============================] - 2s 37us/step - loss: 0.6767 - acc: 0.7484 - val_loss: 0.8122 - val_acc: 0.7103\n",
      "Epoch 32/150\n",
      "49896/49896 [==============================] - 2s 37us/step - loss: 0.6747 - acc: 0.7494 - val_loss: 0.7850 - val_acc: 0.7163\n",
      "Epoch 33/150\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.6697 - acc: 0.7512 - val_loss: 0.7906 - val_acc: 0.7222\n",
      "Epoch 34/150\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.6522 - acc: 0.7551 - val_loss: 0.8021 - val_acc: 0.7242\n",
      "Epoch 35/150\n",
      "49896/49896 [==============================] - 2s 37us/step - loss: 0.6486 - acc: 0.7596 - val_loss: 0.8023 - val_acc: 0.7004\n",
      "Epoch 36/150\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.6378 - acc: 0.7629 - val_loss: 0.7778 - val_acc: 0.7262\n",
      "Epoch 37/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.6408 - acc: 0.7611 - val_loss: 0.8003 - val_acc: 0.7202\n",
      "Epoch 38/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.6403 - acc: 0.7626 - val_loss: 0.8081 - val_acc: 0.7103\n",
      "Epoch 39/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.6251 - acc: 0.7679 - val_loss: 0.7795 - val_acc: 0.7361\n",
      "Epoch 40/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.6255 - acc: 0.7657 - val_loss: 0.8135 - val_acc: 0.7341\n",
      "Epoch 41/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.6109 - acc: 0.7705 - val_loss: 0.7724 - val_acc: 0.7302\n",
      "Epoch 42/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.6156 - acc: 0.7684 - val_loss: 0.7925 - val_acc: 0.7302\n",
      "Epoch 43/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.6032 - acc: 0.7751 - val_loss: 0.7971 - val_acc: 0.7282\n",
      "Epoch 44/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.6028 - acc: 0.7741 - val_loss: 0.7637 - val_acc: 0.7361\n",
      "Epoch 45/150\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.5908 - acc: 0.7794 - val_loss: 0.7750 - val_acc: 0.7381\n",
      "Epoch 46/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.5870 - acc: 0.7812 - val_loss: 0.8424 - val_acc: 0.7282\n",
      "Epoch 47/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.5820 - acc: 0.7829 - val_loss: 0.7742 - val_acc: 0.7202\n",
      "Epoch 48/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5920 - acc: 0.7783 - val_loss: 0.7376 - val_acc: 0.7440\n",
      "Epoch 49/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5705 - acc: 0.7863 - val_loss: 0.7901 - val_acc: 0.7321\n",
      "Epoch 50/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.5760 - acc: 0.7828 - val_loss: 0.8031 - val_acc: 0.7063\n",
      "Epoch 51/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.5674 - acc: 0.7876 - val_loss: 0.7897 - val_acc: 0.7262\n",
      "Epoch 52/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5691 - acc: 0.7875 - val_loss: 0.7932 - val_acc: 0.7341\n",
      "Epoch 53/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.5657 - acc: 0.7869 - val_loss: 0.8326 - val_acc: 0.7242\n",
      "Epoch 54/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.5585 - acc: 0.7901 - val_loss: 0.7985 - val_acc: 0.7202\n",
      "Epoch 55/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.5545 - acc: 0.7919 - val_loss: 0.8164 - val_acc: 0.7143\n",
      "Epoch 56/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5598 - acc: 0.7891 - val_loss: 0.7858 - val_acc: 0.7282\n",
      "Epoch 57/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5500 - acc: 0.7956 - val_loss: 0.7769 - val_acc: 0.7440\n",
      "Epoch 58/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5493 - acc: 0.7922 - val_loss: 0.7848 - val_acc: 0.7321\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5424 - acc: 0.7966 - val_loss: 0.7904 - val_acc: 0.7361\n",
      "Epoch 60/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.5394 - acc: 0.7979 - val_loss: 0.7693 - val_acc: 0.7361\n",
      "Epoch 61/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5387 - acc: 0.7981 - val_loss: 0.8276 - val_acc: 0.7361\n",
      "Epoch 62/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5359 - acc: 0.8005 - val_loss: 0.7758 - val_acc: 0.7321\n",
      "Epoch 63/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5342 - acc: 0.7989 - val_loss: 0.7576 - val_acc: 0.7361\n",
      "Epoch 64/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5263 - acc: 0.8034 - val_loss: 0.7511 - val_acc: 0.7480\n",
      "Epoch 65/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5290 - acc: 0.8013 - val_loss: 0.7819 - val_acc: 0.7302\n",
      "Epoch 66/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5317 - acc: 0.8003 - val_loss: 0.8314 - val_acc: 0.7202\n",
      "Epoch 67/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5303 - acc: 0.8018 - val_loss: 0.7543 - val_acc: 0.7460\n",
      "Epoch 68/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5136 - acc: 0.8068 - val_loss: 0.7832 - val_acc: 0.7222\n",
      "Epoch 69/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5270 - acc: 0.8028 - val_loss: 0.7712 - val_acc: 0.7421\n",
      "Epoch 70/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5120 - acc: 0.8065 - val_loss: 0.7743 - val_acc: 0.7361\n",
      "Epoch 71/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.5116 - acc: 0.8080 - val_loss: 0.7569 - val_acc: 0.7520\n",
      "Epoch 72/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.5070 - acc: 0.8093 - val_loss: 0.7567 - val_acc: 0.7599\n",
      "Epoch 73/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5022 - acc: 0.8127 - val_loss: 0.8011 - val_acc: 0.7460\n",
      "Epoch 74/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5011 - acc: 0.8116 - val_loss: 0.8493 - val_acc: 0.7282\n",
      "Epoch 75/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.5020 - acc: 0.8123 - val_loss: 0.7706 - val_acc: 0.7500\n",
      "Epoch 76/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5016 - acc: 0.8106 - val_loss: 0.7614 - val_acc: 0.7321\n",
      "Epoch 77/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4988 - acc: 0.8129 - val_loss: 0.8008 - val_acc: 0.7222\n",
      "Epoch 78/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.5049 - acc: 0.8103 - val_loss: 0.8503 - val_acc: 0.7302\n",
      "Epoch 79/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4909 - acc: 0.8164 - val_loss: 0.7834 - val_acc: 0.7460\n",
      "Epoch 80/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4893 - acc: 0.8171 - val_loss: 0.8116 - val_acc: 0.7381\n",
      "Epoch 81/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4849 - acc: 0.8181 - val_loss: 0.7592 - val_acc: 0.7579\n",
      "Epoch 82/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4839 - acc: 0.8189 - val_loss: 0.8176 - val_acc: 0.7480\n",
      "Epoch 83/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4852 - acc: 0.8194 - val_loss: 0.7465 - val_acc: 0.7500\n",
      "Epoch 84/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4884 - acc: 0.8180 - val_loss: 0.8452 - val_acc: 0.7321\n",
      "Epoch 85/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4862 - acc: 0.8168 - val_loss: 0.8287 - val_acc: 0.7242\n",
      "Epoch 86/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4781 - acc: 0.8202 - val_loss: 0.8232 - val_acc: 0.7361\n",
      "Epoch 87/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4752 - acc: 0.8221 - val_loss: 0.8355 - val_acc: 0.7341\n",
      "Epoch 88/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4747 - acc: 0.8225 - val_loss: 0.7905 - val_acc: 0.7381\n",
      "Epoch 89/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4826 - acc: 0.8215 - val_loss: 0.8230 - val_acc: 0.7480\n",
      "Epoch 90/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4702 - acc: 0.8260 - val_loss: 0.7747 - val_acc: 0.7440\n",
      "Epoch 91/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4625 - acc: 0.8274 - val_loss: 0.7840 - val_acc: 0.7381\n",
      "Epoch 92/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4640 - acc: 0.8266 - val_loss: 0.7963 - val_acc: 0.7440\n",
      "Epoch 93/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4690 - acc: 0.8249 - val_loss: 0.8017 - val_acc: 0.7361\n",
      "Epoch 94/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4636 - acc: 0.8271 - val_loss: 0.7879 - val_acc: 0.7579\n",
      "Epoch 95/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4615 - acc: 0.8285 - val_loss: 0.8159 - val_acc: 0.7500\n",
      "Epoch 96/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4661 - acc: 0.8258 - val_loss: 0.8235 - val_acc: 0.7321\n",
      "Epoch 97/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4603 - acc: 0.8287 - val_loss: 0.8264 - val_acc: 0.7440\n",
      "Epoch 98/150\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4510 - acc: 0.8336 - val_loss: 0.7905 - val_acc: 0.7421\n",
      "Epoch 99/150\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4597 - acc: 0.8285 - val_loss: 0.8006 - val_acc: 0.7401\n",
      "Epoch 100/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4492 - acc: 0.8326 - val_loss: 0.8170 - val_acc: 0.7718\n",
      "Epoch 101/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4536 - acc: 0.8305 - val_loss: 0.8531 - val_acc: 0.7500\n",
      "Epoch 102/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4560 - acc: 0.8297 - val_loss: 0.8300 - val_acc: 0.7341\n",
      "Epoch 103/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4469 - acc: 0.8319 - val_loss: 0.8002 - val_acc: 0.7421\n",
      "Epoch 104/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4511 - acc: 0.8325 - val_loss: 0.8972 - val_acc: 0.7222\n",
      "Epoch 105/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4545 - acc: 0.8300 - val_loss: 0.8023 - val_acc: 0.7500\n",
      "Epoch 106/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4557 - acc: 0.8308 - val_loss: 0.8294 - val_acc: 0.7361\n",
      "Epoch 107/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4408 - acc: 0.8358 - val_loss: 0.8263 - val_acc: 0.7361\n",
      "Epoch 108/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4406 - acc: 0.8344 - val_loss: 0.8786 - val_acc: 0.7520\n",
      "Epoch 109/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4436 - acc: 0.8340 - val_loss: 0.8272 - val_acc: 0.7520\n",
      "Epoch 110/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4338 - acc: 0.8384 - val_loss: 0.7906 - val_acc: 0.7619\n",
      "Epoch 111/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4359 - acc: 0.8391 - val_loss: 0.8147 - val_acc: 0.7579\n",
      "Epoch 112/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4349 - acc: 0.8387 - val_loss: 0.8070 - val_acc: 0.7460\n",
      "Epoch 113/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4378 - acc: 0.8383 - val_loss: 0.8379 - val_acc: 0.7460\n",
      "Epoch 114/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4336 - acc: 0.8380 - val_loss: 0.8473 - val_acc: 0.7540\n",
      "Epoch 115/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4293 - acc: 0.8403 - val_loss: 0.8541 - val_acc: 0.7659\n",
      "Epoch 116/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4325 - acc: 0.8380 - val_loss: 0.8668 - val_acc: 0.7480\n",
      "Epoch 117/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4325 - acc: 0.8390 - val_loss: 0.8678 - val_acc: 0.7460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4245 - acc: 0.8431 - val_loss: 0.8854 - val_acc: 0.7302\n",
      "Epoch 119/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4247 - acc: 0.8415 - val_loss: 0.9206 - val_acc: 0.7341\n",
      "Epoch 120/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4220 - acc: 0.8415 - val_loss: 0.8699 - val_acc: 0.7639\n",
      "Epoch 121/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4231 - acc: 0.8420 - val_loss: 0.8506 - val_acc: 0.7401\n",
      "Epoch 122/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.4315 - acc: 0.8401 - val_loss: 0.8674 - val_acc: 0.7639\n",
      "Epoch 123/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.4143 - acc: 0.8438 - val_loss: 0.8692 - val_acc: 0.7440\n",
      "Epoch 124/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4231 - acc: 0.8426 - val_loss: 0.8865 - val_acc: 0.7480\n",
      "Epoch 125/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4192 - acc: 0.8431 - val_loss: 0.7934 - val_acc: 0.7579\n",
      "Epoch 126/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4276 - acc: 0.8409 - val_loss: 0.8612 - val_acc: 0.7440\n",
      "Epoch 127/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4183 - acc: 0.8453 - val_loss: 0.8769 - val_acc: 0.7460\n",
      "Epoch 128/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4149 - acc: 0.8444 - val_loss: 0.8938 - val_acc: 0.7440\n",
      "Epoch 129/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4080 - acc: 0.8479 - val_loss: 0.8413 - val_acc: 0.7560\n",
      "Epoch 130/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4066 - acc: 0.8495 - val_loss: 0.9124 - val_acc: 0.7401\n",
      "Epoch 131/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4113 - acc: 0.8469 - val_loss: 0.9585 - val_acc: 0.7222\n",
      "Epoch 132/150\n",
      "49896/49896 [==============================] - 2s 37us/step - loss: 0.4110 - acc: 0.8466 - val_loss: 0.9047 - val_acc: 0.7321\n",
      "Epoch 133/150\n",
      "49896/49896 [==============================] - 2s 41us/step - loss: 0.4052 - acc: 0.8491 - val_loss: 0.9133 - val_acc: 0.7262\n",
      "Epoch 134/150\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4119 - acc: 0.8475 - val_loss: 0.9269 - val_acc: 0.7222\n",
      "Epoch 135/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.4100 - acc: 0.8478 - val_loss: 0.8923 - val_acc: 0.7282\n",
      "Epoch 136/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.3990 - acc: 0.8518 - val_loss: 0.9072 - val_acc: 0.7560\n",
      "Epoch 137/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4039 - acc: 0.8502 - val_loss: 0.9183 - val_acc: 0.7540\n",
      "Epoch 138/150\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.3983 - acc: 0.8519 - val_loss: 0.9098 - val_acc: 0.7560\n",
      "Epoch 139/150\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.3987 - acc: 0.8519 - val_loss: 0.8696 - val_acc: 0.7659\n",
      "Epoch 140/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.3981 - acc: 0.8530 - val_loss: 0.8924 - val_acc: 0.7381\n",
      "Epoch 141/150\n",
      "49896/49896 [==============================] - 2s 32us/step - loss: 0.3989 - acc: 0.8522 - val_loss: 0.8880 - val_acc: 0.7540\n",
      "Epoch 142/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.4002 - acc: 0.8513 - val_loss: 0.9377 - val_acc: 0.7520\n",
      "Epoch 143/150\n",
      "49896/49896 [==============================] - 2s 32us/step - loss: 0.3932 - acc: 0.8543 - val_loss: 0.8727 - val_acc: 0.7421\n",
      "Epoch 144/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.3971 - acc: 0.8546 - val_loss: 0.8919 - val_acc: 0.7579\n",
      "Epoch 145/150\n",
      "49896/49896 [==============================] - 2s 34us/step - loss: 0.3979 - acc: 0.8533 - val_loss: 0.8919 - val_acc: 0.7480\n",
      "Epoch 146/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.3906 - acc: 0.8546 - val_loss: 0.9385 - val_acc: 0.7460\n",
      "Epoch 147/150\n",
      "49896/49896 [==============================] - 2s 32us/step - loss: 0.3959 - acc: 0.8534 - val_loss: 0.9258 - val_acc: 0.7480\n",
      "Epoch 148/150\n",
      "49896/49896 [==============================] - 2s 32us/step - loss: 0.3946 - acc: 0.8528 - val_loss: 0.9589 - val_acc: 0.7421\n",
      "Epoch 149/150\n",
      "49896/49896 [==============================] - 2s 33us/step - loss: 0.3911 - acc: 0.8567 - val_loss: 0.9334 - val_acc: 0.7540\n",
      "Epoch 150/150\n",
      "49896/49896 [==============================] - 2s 32us/step - loss: 0.3853 - acc: 0.8571 - val_loss: 0.8784 - val_acc: 0.7579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fa6b8b35c0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(XhistPlace, y, epochs=150, batch_size=256, validation_split=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49896 samples, validate on 504 samples\n",
      "Epoch 1/300\n",
      "49896/49896 [==============================] - 3s 53us/step - loss: 2.2132 - acc: 0.2063 - val_loss: 1.4604 - val_acc: 0.3274\n",
      "Epoch 2/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 1.3709 - acc: 0.4130 - val_loss: 1.2021 - val_acc: 0.5298\n",
      "Epoch 3/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 1.1784 - acc: 0.5138 - val_loss: 1.1406 - val_acc: 0.5397\n",
      "Epoch 4/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 1.0755 - acc: 0.5488 - val_loss: 1.0624 - val_acc: 0.5774\n",
      "Epoch 5/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 1.0278 - acc: 0.5673 - val_loss: 0.9645 - val_acc: 0.5913\n",
      "Epoch 6/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.9831 - acc: 0.5813 - val_loss: 0.9685 - val_acc: 0.5893\n",
      "Epoch 7/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.9513 - acc: 0.5923 - val_loss: 0.9811 - val_acc: 0.5873\n",
      "Epoch 8/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.9381 - acc: 0.6006 - val_loss: 0.9502 - val_acc: 0.5992\n",
      "Epoch 9/300\n",
      "49896/49896 [==============================] - 2s 45us/step - loss: 0.9075 - acc: 0.6277 - val_loss: 0.9112 - val_acc: 0.6488\n",
      "Epoch 10/300\n",
      "49896/49896 [==============================] - 2s 43us/step - loss: 0.8747 - acc: 0.6612 - val_loss: 0.8818 - val_acc: 0.6647\n",
      "Epoch 11/300\n",
      "49896/49896 [==============================] - 2s 42us/step - loss: 0.8504 - acc: 0.6735 - val_loss: 0.8711 - val_acc: 0.6766\n",
      "Epoch 12/300\n",
      "49896/49896 [==============================] - 2s 38us/step - loss: 0.8347 - acc: 0.6804 - val_loss: 0.8947 - val_acc: 0.6865\n",
      "Epoch 13/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.8061 - acc: 0.6934 - val_loss: 0.8805 - val_acc: 0.6706\n",
      "Epoch 14/300\n",
      "49896/49896 [==============================] - 2s 49us/step - loss: 0.7960 - acc: 0.6988 - val_loss: 0.8488 - val_acc: 0.6825\n",
      "Epoch 15/300\n",
      "49896/49896 [==============================] - 3s 51us/step - loss: 0.7818 - acc: 0.7047 - val_loss: 0.8371 - val_acc: 0.7083\n",
      "Epoch 16/300\n",
      "49896/49896 [==============================] - 2s 47us/step - loss: 0.7660 - acc: 0.7122 - val_loss: 0.8528 - val_acc: 0.6944\n",
      "Epoch 17/300\n",
      "49896/49896 [==============================] - 2s 49us/step - loss: 0.7544 - acc: 0.7183 - val_loss: 0.8131 - val_acc: 0.6964\n",
      "Epoch 18/300\n",
      "49896/49896 [==============================] - 2s 49us/step - loss: 0.7441 - acc: 0.7220 - val_loss: 0.8014 - val_acc: 0.7123\n",
      "Epoch 19/300\n",
      "49896/49896 [==============================] - 2s 43us/step - loss: 0.7292 - acc: 0.7288 - val_loss: 0.8059 - val_acc: 0.7024\n",
      "Epoch 20/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.7285 - acc: 0.7289 - val_loss: 0.8672 - val_acc: 0.6964\n",
      "Epoch 21/300\n",
      "49896/49896 [==============================] - 2s 41us/step - loss: 0.7140 - acc: 0.7358 - val_loss: 0.7796 - val_acc: 0.7103\n",
      "Epoch 22/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.7066 - acc: 0.7390 - val_loss: 0.7917 - val_acc: 0.7183\n",
      "Epoch 23/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.7039 - acc: 0.7400 - val_loss: 0.7869 - val_acc: 0.7123\n",
      "Epoch 24/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.6894 - acc: 0.7471 - val_loss: 0.7584 - val_acc: 0.7143\n",
      "Epoch 25/300\n",
      "49896/49896 [==============================] - 2s 42us/step - loss: 0.6787 - acc: 0.7527 - val_loss: 0.8139 - val_acc: 0.7143\n",
      "Epoch 26/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.6823 - acc: 0.7494 - val_loss: 0.7694 - val_acc: 0.7063\n",
      "Epoch 27/300\n",
      "49896/49896 [==============================] - 2s 41us/step - loss: 0.6656 - acc: 0.7555 - val_loss: 0.7647 - val_acc: 0.7143\n",
      "Epoch 28/300\n",
      "49896/49896 [==============================] - 2s 43us/step - loss: 0.6686 - acc: 0.7555 - val_loss: 0.7821 - val_acc: 0.7123\n",
      "Epoch 29/300\n",
      "49896/49896 [==============================] - 2s 41us/step - loss: 0.6582 - acc: 0.7613 - val_loss: 0.8196 - val_acc: 0.7044\n",
      "Epoch 30/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.6542 - acc: 0.7617 - val_loss: 0.7627 - val_acc: 0.7143\n",
      "Epoch 31/300\n",
      "49896/49896 [==============================] - 2s 42us/step - loss: 0.6444 - acc: 0.7666 - val_loss: 0.7781 - val_acc: 0.7262\n",
      "Epoch 32/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.6424 - acc: 0.7659 - val_loss: 0.7988 - val_acc: 0.7103\n",
      "Epoch 33/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.6439 - acc: 0.7646 - val_loss: 0.8384 - val_acc: 0.7004\n",
      "Epoch 34/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.6372 - acc: 0.7679 - val_loss: 0.7911 - val_acc: 0.7222\n",
      "Epoch 35/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.6318 - acc: 0.7700 - val_loss: 0.7817 - val_acc: 0.7222\n",
      "Epoch 36/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.6194 - acc: 0.7746 - val_loss: 0.7600 - val_acc: 0.7282\n",
      "Epoch 37/300\n",
      "49896/49896 [==============================] - 2s 47us/step - loss: 0.6208 - acc: 0.7733 - val_loss: 0.7494 - val_acc: 0.7302\n",
      "Epoch 38/300\n",
      "49896/49896 [==============================] - 2s 50us/step - loss: 0.6270 - acc: 0.7719 - val_loss: 0.7508 - val_acc: 0.7302\n",
      "Epoch 39/300\n",
      "49896/49896 [==============================] - 3s 52us/step - loss: 0.6194 - acc: 0.7738 - val_loss: 0.7668 - val_acc: 0.7302\n",
      "Epoch 40/300\n",
      "49896/49896 [==============================] - 3s 61us/step - loss: 0.6162 - acc: 0.7741 - val_loss: 0.7623 - val_acc: 0.7321\n",
      "Epoch 41/300\n",
      "49896/49896 [==============================] - 2s 47us/step - loss: 0.6049 - acc: 0.7790 - val_loss: 0.7315 - val_acc: 0.7421\n",
      "Epoch 42/300\n",
      "49896/49896 [==============================] - 3s 50us/step - loss: 0.5982 - acc: 0.7812 - val_loss: 0.7738 - val_acc: 0.7321\n",
      "Epoch 43/300\n",
      "49896/49896 [==============================] - 2s 47us/step - loss: 0.5929 - acc: 0.7837 - val_loss: 0.7637 - val_acc: 0.7361\n",
      "Epoch 44/300\n",
      "49896/49896 [==============================] - 2s 49us/step - loss: 0.5846 - acc: 0.7874 - val_loss: 0.7756 - val_acc: 0.7381\n",
      "Epoch 45/300\n",
      "49896/49896 [==============================] - 2s 50us/step - loss: 0.5805 - acc: 0.7874 - val_loss: 0.8095 - val_acc: 0.7183\n",
      "Epoch 46/300\n",
      "49896/49896 [==============================] - 2s 49us/step - loss: 0.5787 - acc: 0.7888 - val_loss: 0.7520 - val_acc: 0.7440\n",
      "Epoch 47/300\n",
      "49896/49896 [==============================] - 2s 48us/step - loss: 0.5733 - acc: 0.7901 - val_loss: 0.7396 - val_acc: 0.7302\n",
      "Epoch 48/300\n",
      "49896/49896 [==============================] - 2s 48us/step - loss: 0.5758 - acc: 0.7869 - val_loss: 0.7891 - val_acc: 0.7421\n",
      "Epoch 49/300\n",
      "49896/49896 [==============================] - 2s 49us/step - loss: 0.5718 - acc: 0.7916 - val_loss: 0.8204 - val_acc: 0.7262\n",
      "Epoch 50/300\n",
      "49896/49896 [==============================] - 2s 48us/step - loss: 0.5608 - acc: 0.7943 - val_loss: 0.7574 - val_acc: 0.7341\n",
      "Epoch 51/300\n",
      "49896/49896 [==============================] - 2s 47us/step - loss: 0.5589 - acc: 0.7945 - val_loss: 0.7696 - val_acc: 0.7282\n",
      "Epoch 52/300\n",
      "49896/49896 [==============================] - 2s 48us/step - loss: 0.5662 - acc: 0.7921 - val_loss: 0.7858 - val_acc: 0.7202\n",
      "Epoch 53/300\n",
      "49896/49896 [==============================] - 2s 47us/step - loss: 0.5594 - acc: 0.7929 - val_loss: 0.7746 - val_acc: 0.7421\n",
      "Epoch 54/300\n",
      "49896/49896 [==============================] - 2s 50us/step - loss: 0.5514 - acc: 0.7998 - val_loss: 0.7690 - val_acc: 0.7440\n",
      "Epoch 55/300\n",
      "49896/49896 [==============================] - 2s 50us/step - loss: 0.5441 - acc: 0.7999 - val_loss: 0.7801 - val_acc: 0.7282\n",
      "Epoch 56/300\n",
      "49896/49896 [==============================] - 3s 52us/step - loss: 0.5455 - acc: 0.8000 - val_loss: 0.7748 - val_acc: 0.7500\n",
      "Epoch 57/300\n",
      "49896/49896 [==============================] - 2s 48us/step - loss: 0.5432 - acc: 0.7995 - val_loss: 0.7531 - val_acc: 0.7421\n",
      "Epoch 58/300\n",
      "49896/49896 [==============================] - 2s 47us/step - loss: 0.5393 - acc: 0.8020 - val_loss: 0.7997 - val_acc: 0.7302\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49896/49896 [==============================] - 2s 48us/step - loss: 0.5395 - acc: 0.8020 - val_loss: 0.7780 - val_acc: 0.7520\n",
      "Epoch 60/300\n",
      "49896/49896 [==============================] - 3s 54us/step - loss: 0.5328 - acc: 0.8038 - val_loss: 0.7242 - val_acc: 0.7421\n",
      "Epoch 61/300\n",
      "49896/49896 [==============================] - 3s 51us/step - loss: 0.5200 - acc: 0.8077 - val_loss: 0.8125 - val_acc: 0.7440\n",
      "Epoch 62/300\n",
      "49896/49896 [==============================] - 3s 51us/step - loss: 0.5308 - acc: 0.8071 - val_loss: 0.7824 - val_acc: 0.7440\n",
      "Epoch 63/300\n",
      "49896/49896 [==============================] - 2s 43us/step - loss: 0.5163 - acc: 0.8111 - val_loss: 0.7772 - val_acc: 0.7341\n",
      "Epoch 64/300\n",
      "49896/49896 [==============================] - 2s 43us/step - loss: 0.5196 - acc: 0.8113 - val_loss: 0.7547 - val_acc: 0.7401\n",
      "Epoch 65/300\n",
      "49896/49896 [==============================] - 2s 44us/step - loss: 0.5210 - acc: 0.8078 - val_loss: 0.7553 - val_acc: 0.7520\n",
      "Epoch 66/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.5159 - acc: 0.8104 - val_loss: 0.7725 - val_acc: 0.7381\n",
      "Epoch 67/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.5132 - acc: 0.8119 - val_loss: 0.7766 - val_acc: 0.7421\n",
      "Epoch 68/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.5157 - acc: 0.8122 - val_loss: 0.7501 - val_acc: 0.7460\n",
      "Epoch 69/300\n",
      "49896/49896 [==============================] - 2s 41us/step - loss: 0.5129 - acc: 0.8114 - val_loss: 0.8453 - val_acc: 0.7282\n",
      "Epoch 70/300\n",
      "49896/49896 [==============================] - 2s 41us/step - loss: 0.5105 - acc: 0.8144 - val_loss: 0.8288 - val_acc: 0.7361\n",
      "Epoch 71/300\n",
      "49896/49896 [==============================] - 2s 43us/step - loss: 0.5005 - acc: 0.8152 - val_loss: 0.7552 - val_acc: 0.7460\n",
      "Epoch 72/300\n",
      "49896/49896 [==============================] - 2s 42us/step - loss: 0.4933 - acc: 0.8187 - val_loss: 0.7869 - val_acc: 0.7440\n",
      "Epoch 73/300\n",
      "49896/49896 [==============================] - 2s 43us/step - loss: 0.4922 - acc: 0.8201 - val_loss: 0.8094 - val_acc: 0.7381\n",
      "Epoch 74/300\n",
      "49896/49896 [==============================] - 2s 43us/step - loss: 0.4983 - acc: 0.8177 - val_loss: 0.7969 - val_acc: 0.7619\n",
      "Epoch 75/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.4974 - acc: 0.8165 - val_loss: 0.8347 - val_acc: 0.7401\n",
      "Epoch 76/300\n",
      "49896/49896 [==============================] - 2s 42us/step - loss: 0.4863 - acc: 0.8210 - val_loss: 0.8201 - val_acc: 0.7381\n",
      "Epoch 77/300\n",
      "49896/49896 [==============================] - 2s 43us/step - loss: 0.4868 - acc: 0.8206 - val_loss: 0.8712 - val_acc: 0.7381\n",
      "Epoch 78/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.4817 - acc: 0.8233 - val_loss: 0.7724 - val_acc: 0.7560oss: 0.4774 \n",
      "Epoch 79/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.4770 - acc: 0.8262 - val_loss: 0.8079 - val_acc: 0.7540\n",
      "Epoch 80/300\n",
      "49896/49896 [==============================] - 2s 44us/step - loss: 0.4840 - acc: 0.8230 - val_loss: 0.7998 - val_acc: 0.7599\n",
      "Epoch 81/300\n",
      "49896/49896 [==============================] - 2s 41us/step - loss: 0.4852 - acc: 0.8201 - val_loss: 0.8131 - val_acc: 0.7381\n",
      "Epoch 82/300\n",
      "49896/49896 [==============================] - 2s 41us/step - loss: 0.4779 - acc: 0.8251 - val_loss: 0.8383 - val_acc: 0.7460\n",
      "Epoch 83/300\n",
      "49896/49896 [==============================] - 2s 44us/step - loss: 0.4722 - acc: 0.8272 - val_loss: 0.8394 - val_acc: 0.7500\n",
      "Epoch 84/300\n",
      "49896/49896 [==============================] - 2s 43us/step - loss: 0.4738 - acc: 0.8268 - val_loss: 0.8902 - val_acc: 0.7282\n",
      "Epoch 85/300\n",
      "49896/49896 [==============================] - 2s 43us/step - loss: 0.4705 - acc: 0.8267 - val_loss: 0.8311 - val_acc: 0.7460\n",
      "Epoch 86/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.4701 - acc: 0.8274 - val_loss: 0.7868 - val_acc: 0.7500\n",
      "Epoch 87/300\n",
      "49896/49896 [==============================] - 2s 41us/step - loss: 0.4651 - acc: 0.8298 - val_loss: 0.8267 - val_acc: 0.7460\n",
      "Epoch 88/300\n",
      "49896/49896 [==============================] - 2s 42us/step - loss: 0.4707 - acc: 0.8275 - val_loss: 0.9045 - val_acc: 0.7321\n",
      "Epoch 89/300\n",
      "49896/49896 [==============================] - 2s 42us/step - loss: 0.4625 - acc: 0.8305 - val_loss: 0.8627 - val_acc: 0.7341\n",
      "Epoch 90/300\n",
      "49896/49896 [==============================] - ETA: 0s - loss: 0.4655 - acc: 0.829 - 2s 41us/step - loss: 0.4647 - acc: 0.8293 - val_loss: 0.8476 - val_acc: 0.7520\n",
      "Epoch 91/300\n",
      "49896/49896 [==============================] - 2s 42us/step - loss: 0.4590 - acc: 0.8313 - val_loss: 0.8662 - val_acc: 0.7321\n",
      "Epoch 92/300\n",
      "49896/49896 [==============================] - 2s 42us/step - loss: 0.4551 - acc: 0.8324 - val_loss: 0.8419 - val_acc: 0.7520\n",
      "Epoch 93/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.4553 - acc: 0.8330 - val_loss: 0.8383 - val_acc: 0.7500\n",
      "Epoch 94/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.4596 - acc: 0.8296 - val_loss: 0.8814 - val_acc: 0.7401\n",
      "Epoch 95/300\n",
      "49896/49896 [==============================] - 2s 43us/step - loss: 0.4524 - acc: 0.8336 - val_loss: 0.8589 - val_acc: 0.7639\n",
      "Epoch 96/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.4580 - acc: 0.8325 - val_loss: 0.8043 - val_acc: 0.7619\n",
      "Epoch 97/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.4484 - acc: 0.8359 - val_loss: 0.8915 - val_acc: 0.7440\n",
      "Epoch 98/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.4457 - acc: 0.8378 - val_loss: 0.8669 - val_acc: 0.7381\n",
      "Epoch 99/300\n",
      "49896/49896 [==============================] - 2s 38us/step - loss: 0.4467 - acc: 0.8376 - val_loss: 0.8465 - val_acc: 0.7540\n",
      "Epoch 100/300\n",
      "49896/49896 [==============================] - 2s 40us/step - loss: 0.4537 - acc: 0.8338 - val_loss: 0.8864 - val_acc: 0.7341\n",
      "Epoch 101/300\n",
      "49896/49896 [==============================] - 2s 41us/step - loss: 0.4434 - acc: 0.8393 - val_loss: 0.8738 - val_acc: 0.7401\n",
      "Epoch 102/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.4409 - acc: 0.8384 - val_loss: 0.9492 - val_acc: 0.7302\n",
      "Epoch 103/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4484 - acc: 0.8354 - val_loss: 0.9490 - val_acc: 0.7381\n",
      "Epoch 104/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4394 - acc: 0.8390 - val_loss: 0.8980 - val_acc: 0.7341\n",
      "Epoch 105/300\n",
      "49896/49896 [==============================] - 2s 41us/step - loss: 0.4403 - acc: 0.8387 - val_loss: 0.8655 - val_acc: 0.7381\n",
      "Epoch 106/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.4303 - acc: 0.8424 - val_loss: 0.9042 - val_acc: 0.7599\n",
      "Epoch 107/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4317 - acc: 0.8418 - val_loss: 0.8389 - val_acc: 0.7659\n",
      "Epoch 108/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4321 - acc: 0.8435 - val_loss: 0.8987 - val_acc: 0.7599\n",
      "Epoch 109/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4310 - acc: 0.8417 - val_loss: 0.9506 - val_acc: 0.7421\n",
      "Epoch 110/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4266 - acc: 0.8430 - val_loss: 0.9031 - val_acc: 0.7401\n",
      "Epoch 111/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4231 - acc: 0.8458 - val_loss: 0.8903 - val_acc: 0.7639\n",
      "Epoch 112/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4320 - acc: 0.8424 - val_loss: 0.9573 - val_acc: 0.7321\n",
      "Epoch 113/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4213 - acc: 0.8462 - val_loss: 0.9039 - val_acc: 0.7460\n",
      "Epoch 114/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4178 - acc: 0.8464 - val_loss: 0.9068 - val_acc: 0.7401\n",
      "Epoch 115/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.4296 - acc: 0.8421 - val_loss: 0.8993 - val_acc: 0.7540\n",
      "Epoch 116/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4159 - acc: 0.8478 - val_loss: 0.9075 - val_acc: 0.7401\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.4191 - acc: 0.8468 - val_loss: 0.8651 - val_acc: 0.7619\n",
      "Epoch 118/300\n",
      "49896/49896 [==============================] - 2s 42us/step - loss: 0.4151 - acc: 0.8482 - val_loss: 0.8678 - val_acc: 0.7639\n",
      "Epoch 119/300\n",
      "49896/49896 [==============================] - 2s 38us/step - loss: 0.4187 - acc: 0.8453 - val_loss: 0.9808 - val_acc: 0.7460\n",
      "Epoch 120/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4192 - acc: 0.8456 - val_loss: 0.9183 - val_acc: 0.7500\n",
      "Epoch 121/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4160 - acc: 0.8478 - val_loss: 0.9600 - val_acc: 0.7262\n",
      "Epoch 122/300\n",
      "49896/49896 [==============================] - 2s 37us/step - loss: 0.4091 - acc: 0.8502 - val_loss: 0.9174 - val_acc: 0.7579\n",
      "Epoch 123/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4130 - acc: 0.8481 - val_loss: 0.8786 - val_acc: 0.7619\n",
      "Epoch 124/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4088 - acc: 0.8508 - val_loss: 0.9786 - val_acc: 0.7480\n",
      "Epoch 125/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4003 - acc: 0.8539 - val_loss: 0.8953 - val_acc: 0.7361\n",
      "Epoch 126/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4011 - acc: 0.8536 - val_loss: 0.9593 - val_acc: 0.7560\n",
      "Epoch 127/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4068 - acc: 0.8509 - val_loss: 0.9610 - val_acc: 0.7361\n",
      "Epoch 128/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4034 - acc: 0.8526 - val_loss: 0.9132 - val_acc: 0.7401\n",
      "Epoch 129/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.4044 - acc: 0.8529 - val_loss: 0.8985 - val_acc: 0.7500\n",
      "Epoch 130/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.3944 - acc: 0.8550 - val_loss: 0.8574 - val_acc: 0.7540\n",
      "Epoch 131/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4052 - acc: 0.8517 - val_loss: 0.9021 - val_acc: 0.7421\n",
      "Epoch 132/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4007 - acc: 0.8514 - val_loss: 0.8742 - val_acc: 0.7560\n",
      "Epoch 133/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.4076 - acc: 0.8511 - val_loss: 0.8538 - val_acc: 0.7440\n",
      "Epoch 134/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.4031 - acc: 0.8546 - val_loss: 0.8793 - val_acc: 0.7421\n",
      "Epoch 135/300\n",
      "49896/49896 [==============================] - 2s 37us/step - loss: 0.3954 - acc: 0.8558 - val_loss: 0.9550 - val_acc: 0.7460\n",
      "Epoch 136/300\n",
      "49896/49896 [==============================] - 2s 39us/step - loss: 0.3932 - acc: 0.8533 - val_loss: 0.9242 - val_acc: 0.7540\n",
      "Epoch 137/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.3908 - acc: 0.8565 - val_loss: 1.0308 - val_acc: 0.7341\n",
      "Epoch 138/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.3921 - acc: 0.8557 - val_loss: 0.9874 - val_acc: 0.7341\n",
      "Epoch 139/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.3906 - acc: 0.8552 - val_loss: 0.9724 - val_acc: 0.7520\n",
      "Epoch 140/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.3880 - acc: 0.8577 - val_loss: 1.0120 - val_acc: 0.7460\n",
      "Epoch 141/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.3853 - acc: 0.8594 - val_loss: 0.9955 - val_acc: 0.7480\n",
      "Epoch 142/300\n",
      "49896/49896 [==============================] - 2s 37us/step - loss: 0.3867 - acc: 0.8578 - val_loss: 0.9742 - val_acc: 0.7302\n",
      "Epoch 143/300\n",
      "49896/49896 [==============================] - 2s 37us/step - loss: 0.3828 - acc: 0.8587 - val_loss: 0.9443 - val_acc: 0.7460\n",
      "Epoch 144/300\n",
      "49896/49896 [==============================] - 2s 38us/step - loss: 0.3856 - acc: 0.8590 - val_loss: 0.9998 - val_acc: 0.7440\n",
      "Epoch 145/300\n",
      "49896/49896 [==============================] - 2s 38us/step - loss: 0.3813 - acc: 0.8607 - val_loss: 0.9381 - val_acc: 0.7440\n",
      "Epoch 146/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.3830 - acc: 0.8607 - val_loss: 0.9277 - val_acc: 0.7579\n",
      "Epoch 147/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.3904 - acc: 0.8577 - val_loss: 0.9453 - val_acc: 0.7421\n",
      "Epoch 148/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.3785 - acc: 0.8629 - val_loss: 0.9928 - val_acc: 0.7341\n",
      "Epoch 149/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.3749 - acc: 0.8629 - val_loss: 0.9622 - val_acc: 0.7361\n",
      "Epoch 150/300\n",
      "49896/49896 [==============================] - 2s 35us/step - loss: 0.3738 - acc: 0.8635 - val_loss: 0.9910 - val_acc: 0.7540\n",
      "Epoch 151/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.3800 - acc: 0.8615 - val_loss: 0.9897 - val_acc: 0.7440\n",
      "Epoch 152/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.3815 - acc: 0.8592 - val_loss: 1.0873 - val_acc: 0.7361\n",
      "Epoch 153/300\n",
      "49896/49896 [==============================] - 2s 37us/step - loss: 0.3755 - acc: 0.8631 - val_loss: 1.0338 - val_acc: 0.7302\n",
      "Epoch 154/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.3672 - acc: 0.8644 - val_loss: 0.9422 - val_acc: 0.7401\n",
      "Epoch 155/300\n",
      "49896/49896 [==============================] - 2s 36us/step - loss: 0.3635 - acc: 0.8667 - val_loss: 1.0663 - val_acc: 0.7321\n",
      "Epoch 156/300\n",
      "49896/49896 [==============================] - 2s 37us/step - loss: 0.3772 - acc: 0.8617 - val_loss: 1.0680 - val_acc: 0.7460\n",
      "Epoch 157/300\n",
      "43008/49896 [========================>.....] - ETA: 0s - loss: 0.3631 - acc: 0.8682"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-bcf2f4f74d9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXhistPlace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2332\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2333\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\magiclearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=bins * 3 + 9, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(16, activation='relu'))\n",
    "#model.add(Dense(8, activation='relu'))\n",
    "#model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(categories, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(XhistPlace, y, epochs=300, batch_size=256, validation_split=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50148 samples, validate on 252 samples\n",
      "Epoch 1/100\n",
      "50148/50148 [==============================] - 2s 44us/step - loss: 8.0306 - acc: 0.4336 - val_loss: 5.5937 - val_acc: 0.5159\n",
      "Epoch 2/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 2.9444 - acc: 0.5468 - val_loss: 1.3959 - val_acc: 0.5833\n",
      "Epoch 3/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 1.2060 - acc: 0.6241 - val_loss: 1.1110 - val_acc: 0.6429\n",
      "Epoch 4/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.9733 - acc: 0.6660 - val_loss: 0.9708 - val_acc: 0.6230\n",
      "Epoch 5/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.8872 - acc: 0.6841 - val_loss: 0.9440 - val_acc: 0.6468\n",
      "Epoch 6/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.8379 - acc: 0.6999 - val_loss: 0.8568 - val_acc: 0.6706\n",
      "Epoch 7/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.8050 - acc: 0.7068 - val_loss: 0.9378 - val_acc: 0.6746\n",
      "Epoch 8/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.7832 - acc: 0.7167 - val_loss: 0.7985 - val_acc: 0.6984\n",
      "Epoch 9/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.7467 - acc: 0.7281 - val_loss: 0.8161 - val_acc: 0.7222\n",
      "Epoch 10/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.7311 - acc: 0.7320 - val_loss: 0.7821 - val_acc: 0.7024\n",
      "Epoch 11/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.7276 - acc: 0.7342 - val_loss: 0.8901 - val_acc: 0.6825\n",
      "Epoch 12/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.7133 - acc: 0.7396 - val_loss: 0.8377 - val_acc: 0.7222\n",
      "Epoch 13/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.7130 - acc: 0.7387 - val_loss: 0.8677 - val_acc: 0.6706\n",
      "Epoch 14/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.6972 - acc: 0.7423 - val_loss: 0.7968 - val_acc: 0.7341\n",
      "Epoch 15/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.6819 - acc: 0.7508 - val_loss: 0.7986 - val_acc: 0.7024\n",
      "Epoch 16/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.6649 - acc: 0.7558 - val_loss: 0.7907 - val_acc: 0.7143\n",
      "Epoch 17/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.6598 - acc: 0.7575 - val_loss: 0.7652 - val_acc: 0.7460\n",
      "Epoch 18/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.6499 - acc: 0.7595 - val_loss: 0.8002 - val_acc: 0.7143\n",
      "Epoch 19/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.6456 - acc: 0.7609 - val_loss: 0.8026 - val_acc: 0.6984\n",
      "Epoch 20/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.6344 - acc: 0.7692 - val_loss: 0.7236 - val_acc: 0.7262\n",
      "Epoch 21/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.6313 - acc: 0.7678 - val_loss: 0.8061 - val_acc: 0.7103\n",
      "Epoch 22/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.6312 - acc: 0.7655 - val_loss: 0.7813 - val_acc: 0.7103\n",
      "Epoch 23/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.6396 - acc: 0.7639 - val_loss: 0.7437 - val_acc: 0.7143\n",
      "Epoch 24/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.6298 - acc: 0.7678 - val_loss: 0.8019 - val_acc: 0.7103\n",
      "Epoch 25/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.6171 - acc: 0.7721 - val_loss: 0.7939 - val_acc: 0.7103\n",
      "Epoch 26/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5925 - acc: 0.7827 - val_loss: 0.8538 - val_acc: 0.7024\n",
      "Epoch 27/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.6035 - acc: 0.7755 - val_loss: 0.7893 - val_acc: 0.7341\n",
      "Epoch 28/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5960 - acc: 0.7790 - val_loss: 0.7564 - val_acc: 0.7381\n",
      "Epoch 29/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.6025 - acc: 0.7759 - val_loss: 0.7629 - val_acc: 0.7302 - loss: 0.6025 - acc: 0.775\n",
      "Epoch 30/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5864 - acc: 0.7833 - val_loss: 0.8223 - val_acc: 0.7262\n",
      "Epoch 31/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.6018 - acc: 0.7746 - val_loss: 0.7672 - val_acc: 0.7103\n",
      "Epoch 32/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.5867 - acc: 0.7794 - val_loss: 0.7549 - val_acc: 0.7143\n",
      "Epoch 33/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5806 - acc: 0.7836 - val_loss: 0.7443 - val_acc: 0.7381\n",
      "Epoch 34/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5728 - acc: 0.7856 - val_loss: 0.7650 - val_acc: 0.7460\n",
      "Epoch 35/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.5723 - acc: 0.7869 - val_loss: 0.7805 - val_acc: 0.7262\n",
      "Epoch 36/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5694 - acc: 0.7892 - val_loss: 0.7510 - val_acc: 0.7341\n",
      "Epoch 37/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5595 - acc: 0.7923 - val_loss: 0.7314 - val_acc: 0.7579\n",
      "Epoch 38/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5738 - acc: 0.7853 - val_loss: 0.7671 - val_acc: 0.7460\n",
      "Epoch 39/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5649 - acc: 0.7902 - val_loss: 0.8593 - val_acc: 0.7063\n",
      "Epoch 40/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.5599 - acc: 0.7917 - val_loss: 0.7801 - val_acc: 0.7381\n",
      "Epoch 41/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5502 - acc: 0.7948 - val_loss: 0.7830 - val_acc: 0.7222\n",
      "Epoch 42/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5485 - acc: 0.7956 - val_loss: 0.8119 - val_acc: 0.7024\n",
      "Epoch 43/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5344 - acc: 0.8002 - val_loss: 0.8923 - val_acc: 0.7024\n",
      "Epoch 44/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5484 - acc: 0.7959 - val_loss: 0.7446 - val_acc: 0.7540\n",
      "Epoch 45/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.5442 - acc: 0.7971 - val_loss: 0.8403 - val_acc: 0.7143\n",
      "Epoch 46/100\n",
      "50148/50148 [==============================] - 1s 23us/step - loss: 0.5415 - acc: 0.7961 - val_loss: 0.8416 - val_acc: 0.7183\n",
      "Epoch 47/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.5329 - acc: 0.7996 - val_loss: 0.8660 - val_acc: 0.7024\n",
      "Epoch 48/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.5420 - acc: 0.7978 - val_loss: 0.8318 - val_acc: 0.7183\n",
      "Epoch 49/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.5320 - acc: 0.8008 - val_loss: 0.8854 - val_acc: 0.7222\n",
      "Epoch 50/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.5392 - acc: 0.7967 - val_loss: 0.7622 - val_acc: 0.7183\n",
      "Epoch 51/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.5335 - acc: 0.8009 - val_loss: 0.7769 - val_acc: 0.7302\n",
      "Epoch 52/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.5197 - acc: 0.8049 - val_loss: 0.7768 - val_acc: 0.7302\n",
      "Epoch 53/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.5277 - acc: 0.8027 - val_loss: 0.8600 - val_acc: 0.7262\n",
      "Epoch 54/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.5209 - acc: 0.8052 - val_loss: 0.8404 - val_acc: 0.7262\n",
      "Epoch 55/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.5150 - acc: 0.8071 - val_loss: 0.8005 - val_acc: 0.7183\n",
      "Epoch 56/100\n",
      "50148/50148 [==============================] - ETA: 0s - loss: 0.5037 - acc: 0.810 - 1s 27us/step - loss: 0.5030 - acc: 0.8107 - val_loss: 0.8467 - val_acc: 0.7341\n",
      "Epoch 57/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.5113 - acc: 0.8081 - val_loss: 0.8739 - val_acc: 0.7024\n",
      "Epoch 58/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.5066 - acc: 0.8112 - val_loss: 0.8113 - val_acc: 0.7500\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.4974 - acc: 0.8139 - val_loss: 0.8337 - val_acc: 0.7381\n",
      "Epoch 60/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.5033 - acc: 0.8112 - val_loss: 0.8574 - val_acc: 0.7222\n",
      "Epoch 61/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.5010 - acc: 0.8130 - val_loss: 0.8574 - val_acc: 0.7222\n",
      "Epoch 62/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.4983 - acc: 0.8144 - val_loss: 1.0042 - val_acc: 0.6865\n",
      "Epoch 63/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.4998 - acc: 0.8095 - val_loss: 0.7978 - val_acc: 0.7381\n",
      "Epoch 64/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.4948 - acc: 0.8147 - val_loss: 0.8697 - val_acc: 0.7143\n",
      "Epoch 65/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.4982 - acc: 0.8134 - val_loss: 0.8389 - val_acc: 0.7381\n",
      "Epoch 66/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.4971 - acc: 0.8126 - val_loss: 0.8714 - val_acc: 0.7103\n",
      "Epoch 67/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.4830 - acc: 0.8164 - val_loss: 0.8980 - val_acc: 0.7222\n",
      "Epoch 68/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.4807 - acc: 0.8192 - val_loss: 0.7917 - val_acc: 0.7143\n",
      "Epoch 69/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.4783 - acc: 0.8193 - val_loss: 0.8374 - val_acc: 0.7381\n",
      "Epoch 70/100\n",
      "50148/50148 [==============================] - 1s 28us/step - loss: 0.4762 - acc: 0.8216 - val_loss: 0.9299 - val_acc: 0.7143\n",
      "Epoch 71/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.4838 - acc: 0.8178 - val_loss: 0.7887 - val_acc: 0.7500\n",
      "Epoch 72/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.4821 - acc: 0.8172 - val_loss: 0.8046 - val_acc: 0.7183\n",
      "Epoch 73/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.4749 - acc: 0.8199 - val_loss: 0.7750 - val_acc: 0.7579\n",
      "Epoch 74/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.4805 - acc: 0.8194 - val_loss: 0.8527 - val_acc: 0.7302\n",
      "Epoch 75/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.4560 - acc: 0.8278 - val_loss: 0.7825 - val_acc: 0.7619\n",
      "Epoch 76/100\n",
      "50148/50148 [==============================] - 1s 29us/step - loss: 0.4674 - acc: 0.8234 - val_loss: 0.7975 - val_acc: 0.7460\n",
      "Epoch 77/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.4610 - acc: 0.8267 - val_loss: 0.8407 - val_acc: 0.7619\n",
      "Epoch 78/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.4668 - acc: 0.8248 - val_loss: 0.8845 - val_acc: 0.7341\n",
      "Epoch 79/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.4649 - acc: 0.8249 - val_loss: 0.9694 - val_acc: 0.6944\n",
      "Epoch 80/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.4617 - acc: 0.8257 - val_loss: 0.8665 - val_acc: 0.7302\n",
      "Epoch 81/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.4537 - acc: 0.8283 - val_loss: 0.8595 - val_acc: 0.7103\n",
      "Epoch 82/100\n",
      "50148/50148 [==============================] - 1s 29us/step - loss: 0.4592 - acc: 0.8266 - val_loss: 0.8055 - val_acc: 0.7063\n",
      "Epoch 83/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.4497 - acc: 0.8299 - val_loss: 0.8946 - val_acc: 0.7262\n",
      "Epoch 84/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.4566 - acc: 0.8279 - val_loss: 0.9431 - val_acc: 0.7302\n",
      "Epoch 85/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.4540 - acc: 0.8283 - val_loss: 0.7532 - val_acc: 0.7103\n",
      "Epoch 86/100\n",
      "50148/50148 [==============================] - 1s 29us/step - loss: 0.4521 - acc: 0.8291 - val_loss: 0.7731 - val_acc: 0.7421\n",
      "Epoch 87/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.4467 - acc: 0.8318 - val_loss: 0.8488 - val_acc: 0.7143\n",
      "Epoch 88/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.4474 - acc: 0.8301 - val_loss: 0.7660 - val_acc: 0.7421\n",
      "Epoch 89/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.4493 - acc: 0.8301 - val_loss: 0.8752 - val_acc: 0.7341\n",
      "Epoch 90/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.4347 - acc: 0.8355 - val_loss: 0.8917 - val_acc: 0.7421\n",
      "Epoch 91/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.4385 - acc: 0.8335 - val_loss: 0.8649 - val_acc: 0.7302\n",
      "Epoch 92/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.4297 - acc: 0.8375 - val_loss: 0.8560 - val_acc: 0.7421\n",
      "Epoch 93/100\n",
      "50148/50148 [==============================] - 1s 28us/step - loss: 0.4284 - acc: 0.8381 - val_loss: 0.8401 - val_acc: 0.7302\n",
      "Epoch 94/100\n",
      "50148/50148 [==============================] - 1s 28us/step - loss: 0.4291 - acc: 0.8394 - val_loss: 0.8602 - val_acc: 0.7024\n",
      "Epoch 95/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.4315 - acc: 0.8364 - val_loss: 0.8134 - val_acc: 0.7341\n",
      "Epoch 96/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.4281 - acc: 0.8375 - val_loss: 0.8267 - val_acc: 0.7421\n",
      "Epoch 97/100\n",
      "50148/50148 [==============================] - 1s 26us/step - loss: 0.4235 - acc: 0.8405 - val_loss: 0.9018 - val_acc: 0.7421\n",
      "Epoch 98/100\n",
      "50148/50148 [==============================] - 1s 27us/step - loss: 0.4368 - acc: 0.8362 - val_loss: 0.8169 - val_acc: 0.7421\n",
      "Epoch 99/100\n",
      "50148/50148 [==============================] - 1s 24us/step - loss: 0.4212 - acc: 0.8392 - val_loss: 0.8060 - val_acc: 0.7421\n",
      "Epoch 100/100\n",
      "50148/50148 [==============================] - 1s 25us/step - loss: 0.4151 - acc: 0.8441 - val_loss: 0.8096 - val_acc: 0.7302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fa749ddc88>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=bins * 3 + 9, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(16, activation='relu'))\n",
    "#model.add(Dense(8, activation='relu'))\n",
    "#model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(categories, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(XhistPlace, y, epochs=100, batch_size=512, validation_split=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1012  190   18  103  334  108   35]\n",
      " [ 143 1422    5  121   57   37   15]\n",
      " [   8    1 1769    0    3    0   19]\n",
      " [ 127  232    7 1105  291   24   14]\n",
      " [ 141   70    9  170 1351   24   35]\n",
      " [  50   29    1    8    8 1704    0]\n",
      " [  30   19   52   11   53    0 1635]]\n",
      "0.7934920634920635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.66975513, 0.72440143, 0.95056421, 0.72793149, 0.6442537 ,\n",
       "        0.89826041, 0.93268682]),\n",
       " array([0.56222222, 0.79      , 0.98277778, 0.61388889, 0.75055556,\n",
       "        0.94666667, 0.90833333]),\n",
       " array([0.61129568, 0.75577996, 0.96640262, 0.66606389, 0.69335386,\n",
       "        0.92182851, 0.920349  ]),\n",
       " array([1800, 1800, 1800, 1800, 1800, 1800, 1800], dtype=int64))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XhistPlace_test = np.hstack((Xtest_hist, testPlaces))\n",
    "predict = model.predict(XhistPlace_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest.argmax(axis=1), predict.argmax(axis=1)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(ytest.argmax(axis=1), predict.argmax(axis=1)))\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(ytest.argmax(axis=1), predict.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50148 samples, validate on 252 samples\n",
      "Epoch 1/100\n",
      "50148/50148 [==============================] - 4s 86us/step - loss: 1.7403 - acc: 0.3953 - val_loss: 1.1935 - val_acc: 0.5159\n",
      "Epoch 2/100\n",
      "50148/50148 [==============================] - 3s 59us/step - loss: 1.1599 - acc: 0.5398 - val_loss: 1.0075 - val_acc: 0.5675\n",
      "Epoch 3/100\n",
      "50148/50148 [==============================] - 3s 59us/step - loss: 1.0348 - acc: 0.5899 - val_loss: 0.9631 - val_acc: 0.6230\n",
      "Epoch 4/100\n",
      "50148/50148 [==============================] - 3s 62us/step - loss: 0.9752 - acc: 0.6185 - val_loss: 0.9273 - val_acc: 0.6587\n",
      "Epoch 5/100\n",
      "50148/50148 [==============================] - 3s 61us/step - loss: 0.9357 - acc: 0.6429 - val_loss: 0.8153 - val_acc: 0.7103\n",
      "Epoch 6/100\n",
      "50148/50148 [==============================] - 3s 64us/step - loss: 0.9004 - acc: 0.6570 - val_loss: 0.8558 - val_acc: 0.6587\n",
      "Epoch 7/100\n",
      "50148/50148 [==============================] - 3s 65us/step - loss: 0.8649 - acc: 0.6735 - val_loss: 0.8217 - val_acc: 0.6984\n",
      "Epoch 8/100\n",
      "50148/50148 [==============================] - 3s 65us/step - loss: 0.8419 - acc: 0.6814 - val_loss: 0.7598 - val_acc: 0.6984\n",
      "Epoch 9/100\n",
      "50148/50148 [==============================] - 3s 63us/step - loss: 0.8185 - acc: 0.6912 - val_loss: 0.7742 - val_acc: 0.6905\n",
      "Epoch 10/100\n",
      "50148/50148 [==============================] - 3s 67us/step - loss: 0.8044 - acc: 0.6969 - val_loss: 0.7939 - val_acc: 0.7063\n",
      "Epoch 11/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.7957 - acc: 0.7013 - val_loss: 0.7796 - val_acc: 0.7063\n",
      "Epoch 12/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.7850 - acc: 0.7048 - val_loss: 0.7484 - val_acc: 0.7103\n",
      "Epoch 13/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.7724 - acc: 0.7078 - val_loss: 0.7828 - val_acc: 0.6944\n",
      "Epoch 14/100\n",
      "50148/50148 [==============================] - 3s 67us/step - loss: 0.7679 - acc: 0.7112 - val_loss: 0.7995 - val_acc: 0.6746\n",
      "Epoch 15/100\n",
      "50148/50148 [==============================] - 3s 68us/step - loss: 0.7634 - acc: 0.7136 - val_loss: 0.8308 - val_acc: 0.6825\n",
      "Epoch 16/100\n",
      "50148/50148 [==============================] - 3s 59us/step - loss: 0.7514 - acc: 0.7184 - val_loss: 0.8138 - val_acc: 0.6905\n",
      "Epoch 17/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.7487 - acc: 0.7179 - val_loss: 0.8000 - val_acc: 0.6984\n",
      "Epoch 18/100\n",
      "50148/50148 [==============================] - 3s 59us/step - loss: 0.7416 - acc: 0.7226 - val_loss: 0.8410 - val_acc: 0.6746\n",
      "Epoch 19/100\n",
      "50148/50148 [==============================] - 3s 59us/step - loss: 0.7368 - acc: 0.7239 - val_loss: 0.7992 - val_acc: 0.7024\n",
      "Epoch 20/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.7282 - acc: 0.7290 - val_loss: 0.7457 - val_acc: 0.7183\n",
      "Epoch 21/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.7250 - acc: 0.7301 - val_loss: 0.7498 - val_acc: 0.7262\n",
      "Epoch 22/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.7202 - acc: 0.7302 - val_loss: 0.7517 - val_acc: 0.7103\n",
      "Epoch 23/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.7148 - acc: 0.7338 - val_loss: 0.7573 - val_acc: 0.6944\n",
      "Epoch 24/100\n",
      "50148/50148 [==============================] - 3s 59us/step - loss: 0.7068 - acc: 0.7376 - val_loss: 0.7842 - val_acc: 0.6984\n",
      "Epoch 25/100\n",
      "50148/50148 [==============================] - 3s 67us/step - loss: 0.7052 - acc: 0.7366 - val_loss: 0.7532 - val_acc: 0.7063\n",
      "Epoch 26/100\n",
      "50148/50148 [==============================] - 3s 69us/step - loss: 0.6963 - acc: 0.7402 - val_loss: 0.7264 - val_acc: 0.7262\n",
      "Epoch 27/100\n",
      "50148/50148 [==============================] - 3s 68us/step - loss: 0.6956 - acc: 0.7393 - val_loss: 0.7673 - val_acc: 0.7103\n",
      "Epoch 28/100\n",
      "50148/50148 [==============================] - 4s 71us/step - loss: 0.6900 - acc: 0.7420 - val_loss: 0.7511 - val_acc: 0.7302\n",
      "Epoch 29/100\n",
      "50148/50148 [==============================] - 3s 68us/step - loss: 0.6907 - acc: 0.7411 - val_loss: 0.7598 - val_acc: 0.7302\n",
      "Epoch 30/100\n",
      "50148/50148 [==============================] - 4s 72us/step - loss: 0.6844 - acc: 0.7458 - val_loss: 0.7427 - val_acc: 0.7302\n",
      "Epoch 31/100\n",
      "50148/50148 [==============================] - 4s 72us/step - loss: 0.6810 - acc: 0.7472 - val_loss: 0.7424 - val_acc: 0.7143\n",
      "Epoch 32/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.6810 - acc: 0.7463 - val_loss: 0.7297 - val_acc: 0.7143\n",
      "Epoch 33/100\n",
      "50148/50148 [==============================] - 3s 67us/step - loss: 0.6786 - acc: 0.7483 - val_loss: 0.7501 - val_acc: 0.7143\n",
      "Epoch 34/100\n",
      "50148/50148 [==============================] - 3s 67us/step - loss: 0.6750 - acc: 0.7479 - val_loss: 0.7278 - val_acc: 0.7302\n",
      "Epoch 35/100\n",
      "50148/50148 [==============================] - 3s 69us/step - loss: 0.6681 - acc: 0.7515 - val_loss: 0.7400 - val_acc: 0.7103\n",
      "Epoch 36/100\n",
      "50148/50148 [==============================] - 3s 67us/step - loss: 0.6703 - acc: 0.7495 - val_loss: 0.7609 - val_acc: 0.7024\n",
      "Epoch 37/100\n",
      "50148/50148 [==============================] - 3s 67us/step - loss: 0.6696 - acc: 0.7509 - val_loss: 0.7375 - val_acc: 0.7460\n",
      "Epoch 38/100\n",
      "50148/50148 [==============================] - 3s 68us/step - loss: 0.6672 - acc: 0.7515 - val_loss: 0.7184 - val_acc: 0.7421\n",
      "Epoch 39/100\n",
      "50148/50148 [==============================] - ETA: 0s - loss: 0.6707 - acc: 0.749 - 3s 68us/step - loss: 0.6707 - acc: 0.7490 - val_loss: 0.7316 - val_acc: 0.7262\n",
      "Epoch 40/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.6642 - acc: 0.7525 - val_loss: 0.7615 - val_acc: 0.7381\n",
      "Epoch 41/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.6617 - acc: 0.7537 - val_loss: 0.7441 - val_acc: 0.7143\n",
      "Epoch 42/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.6587 - acc: 0.7537 - val_loss: 0.7739 - val_acc: 0.7222\n",
      "Epoch 43/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.6569 - acc: 0.7544 - val_loss: 0.7561 - val_acc: 0.7183\n",
      "Epoch 44/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.6559 - acc: 0.7555 - val_loss: 0.7487 - val_acc: 0.7262\n",
      "Epoch 45/100\n",
      "50148/50148 [==============================] - 3s 64us/step - loss: 0.6562 - acc: 0.7559 - val_loss: 0.7337 - val_acc: 0.7222\n",
      "Epoch 46/100\n",
      "50148/50148 [==============================] - 3s 67us/step - loss: 0.6529 - acc: 0.7571 - val_loss: 0.6922 - val_acc: 0.7302\n",
      "Epoch 47/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.6515 - acc: 0.7592 - val_loss: 0.7198 - val_acc: 0.7381\n",
      "Epoch 48/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.6503 - acc: 0.7586 - val_loss: 0.7184 - val_acc: 0.7421\n",
      "Epoch 49/100\n",
      "50148/50148 [==============================] - 3s 68us/step - loss: 0.6480 - acc: 0.7582 - val_loss: 0.7038 - val_acc: 0.7183\n",
      "Epoch 50/100\n",
      "50148/50148 [==============================] - 4s 74us/step - loss: 0.6468 - acc: 0.7598 - val_loss: 0.6974 - val_acc: 0.7341\n",
      "Epoch 51/100\n",
      "50148/50148 [==============================] - 3s 65us/step - loss: 0.6444 - acc: 0.7608 - val_loss: 0.7217 - val_acc: 0.7143\n",
      "Epoch 52/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.6440 - acc: 0.7596 - val_loss: 0.7257 - val_acc: 0.7302\n",
      "Epoch 53/100\n",
      "50148/50148 [==============================] - 4s 72us/step - loss: 0.6411 - acc: 0.7600 - val_loss: 0.7341 - val_acc: 0.7341\n",
      "Epoch 54/100\n",
      "50148/50148 [==============================] - 3s 67us/step - loss: 0.6417 - acc: 0.7612 - val_loss: 0.7179 - val_acc: 0.7222\n",
      "Epoch 55/100\n",
      "50148/50148 [==============================] - 3s 68us/step - loss: 0.6390 - acc: 0.7622 - val_loss: 0.7371 - val_acc: 0.7302\n",
      "Epoch 56/100\n",
      "50148/50148 [==============================] - 3s 67us/step - loss: 0.6402 - acc: 0.7606 - val_loss: 0.7485 - val_acc: 0.7262\n",
      "Epoch 57/100\n",
      "50148/50148 [==============================] - 3s 67us/step - loss: 0.6405 - acc: 0.7611 - val_loss: 0.7391 - val_acc: 0.7421\n",
      "Epoch 58/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.6389 - acc: 0.7615 - val_loss: 0.7020 - val_acc: 0.7103\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50148/50148 [==============================] - 3s 65us/step - loss: 0.6341 - acc: 0.7652 - val_loss: 0.7000 - val_acc: 0.7302\n",
      "Epoch 60/100\n",
      "50148/50148 [==============================] - 3s 65us/step - loss: 0.6354 - acc: 0.7641 - val_loss: 0.7230 - val_acc: 0.7222\n",
      "Epoch 61/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.6388 - acc: 0.7630 - val_loss: 0.7321 - val_acc: 0.7222\n",
      "Epoch 62/100\n",
      "50148/50148 [==============================] - 3s 65us/step - loss: 0.6365 - acc: 0.7624 - val_loss: 0.7717 - val_acc: 0.7103\n",
      "Epoch 63/100\n",
      "50148/50148 [==============================] - 3s 65us/step - loss: 0.6357 - acc: 0.7626 - val_loss: 0.7420 - val_acc: 0.7103\n",
      "Epoch 64/100\n",
      "50148/50148 [==============================] - 3s 67us/step - loss: 0.6330 - acc: 0.7639 - val_loss: 0.7207 - val_acc: 0.7103\n",
      "Epoch 65/100\n",
      "50148/50148 [==============================] - 3s 66us/step - loss: 0.6316 - acc: 0.7655 - val_loss: 0.7432 - val_acc: 0.7222\n",
      "Epoch 66/100\n",
      "50148/50148 [==============================] - 3s 65us/step - loss: 0.6324 - acc: 0.7646 - val_loss: 0.7198 - val_acc: 0.7341\n",
      "Epoch 67/100\n",
      "50148/50148 [==============================] - 3s 67us/step - loss: 0.6292 - acc: 0.7659 - val_loss: 0.7478 - val_acc: 0.7302\n",
      "Epoch 68/100\n",
      "50148/50148 [==============================] - ETA: 0s - loss: 0.6309 - acc: 0.764 - 4s 71us/step - loss: 0.6312 - acc: 0.7647 - val_loss: 0.6994 - val_acc: 0.7222\n",
      "Epoch 69/100\n",
      "50148/50148 [==============================] - 3s 64us/step - loss: 0.6251 - acc: 0.7674 - val_loss: 0.7038 - val_acc: 0.7302\n",
      "Epoch 70/100\n",
      "50148/50148 [==============================] - 3s 62us/step - loss: 0.6265 - acc: 0.7663 - val_loss: 0.7204 - val_acc: 0.7302\n",
      "Epoch 71/100\n",
      "50148/50148 [==============================] - 3s 63us/step - loss: 0.6267 - acc: 0.7680 - val_loss: 0.6997 - val_acc: 0.7262\n",
      "Epoch 72/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6266 - acc: 0.7658 - val_loss: 0.7261 - val_acc: 0.7381\n",
      "Epoch 73/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6253 - acc: 0.7668 - val_loss: 0.6995 - val_acc: 0.7381\n",
      "Epoch 74/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6231 - acc: 0.7677 - val_loss: 0.7214 - val_acc: 0.7421\n",
      "Epoch 75/100\n",
      "50148/50148 [==============================] - 3s 57us/step - loss: 0.6206 - acc: 0.7687 - val_loss: 0.6749 - val_acc: 0.7500\n",
      "Epoch 76/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6223 - acc: 0.7687 - val_loss: 0.7211 - val_acc: 0.7381\n",
      "Epoch 77/100\n",
      "50148/50148 [==============================] - 3s 57us/step - loss: 0.6223 - acc: 0.7675 - val_loss: 0.7279 - val_acc: 0.7063\n",
      "Epoch 78/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6196 - acc: 0.7680 - val_loss: 0.7377 - val_acc: 0.7103\n",
      "Epoch 79/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6216 - acc: 0.7689 - val_loss: 0.7703 - val_acc: 0.7183\n",
      "Epoch 80/100\n",
      "50148/50148 [==============================] - 3s 57us/step - loss: 0.6213 - acc: 0.7697 - val_loss: 0.7253 - val_acc: 0.7143\n",
      "Epoch 81/100\n",
      "50148/50148 [==============================] - 3s 57us/step - loss: 0.6193 - acc: 0.7702 - val_loss: 0.7806 - val_acc: 0.7063\n",
      "Epoch 82/100\n",
      "50148/50148 [==============================] - 3s 57us/step - loss: 0.6154 - acc: 0.7703 - val_loss: 0.7415 - val_acc: 0.7222\n",
      "Epoch 83/100\n",
      "50148/50148 [==============================] - 3s 57us/step - loss: 0.6170 - acc: 0.7706 - val_loss: 0.7516 - val_acc: 0.7183\n",
      "Epoch 84/100\n",
      "50148/50148 [==============================] - 3s 57us/step - loss: 0.6197 - acc: 0.7685 - val_loss: 0.7402 - val_acc: 0.7143\n",
      "Epoch 85/100\n",
      "50148/50148 [==============================] - 3s 57us/step - loss: 0.6151 - acc: 0.7700 - val_loss: 0.7333 - val_acc: 0.7421\n",
      "Epoch 86/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6154 - acc: 0.7714 - val_loss: 0.7068 - val_acc: 0.7540\n",
      "Epoch 87/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6134 - acc: 0.7718 - val_loss: 0.7047 - val_acc: 0.7262\n",
      "Epoch 88/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6120 - acc: 0.7718 - val_loss: 0.7413 - val_acc: 0.6984\n",
      "Epoch 89/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6117 - acc: 0.7726 - val_loss: 0.7288 - val_acc: 0.7103\n",
      "Epoch 90/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6131 - acc: 0.7720 - val_loss: 0.7520 - val_acc: 0.7063\n",
      "Epoch 91/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6109 - acc: 0.7725 - val_loss: 0.6990 - val_acc: 0.7341\n",
      "Epoch 92/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6119 - acc: 0.7720 - val_loss: 0.7110 - val_acc: 0.7302\n",
      "Epoch 93/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6096 - acc: 0.7716 - val_loss: 0.7318 - val_acc: 0.7262\n",
      "Epoch 94/100\n",
      "50148/50148 [==============================] - 3s 59us/step - loss: 0.6109 - acc: 0.7722 - val_loss: 0.7102 - val_acc: 0.7222\n",
      "Epoch 95/100\n",
      "50148/50148 [==============================] - 3s 57us/step - loss: 0.6095 - acc: 0.7720 - val_loss: 0.7258 - val_acc: 0.7341\n",
      "Epoch 96/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6095 - acc: 0.7729 - val_loss: 0.7482 - val_acc: 0.7302\n",
      "Epoch 97/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6077 - acc: 0.7743 - val_loss: 0.7051 - val_acc: 0.7262\n",
      "Epoch 98/100\n",
      "50148/50148 [==============================] - 3s 58us/step - loss: 0.6086 - acc: 0.7721 - val_loss: 0.7358 - val_acc: 0.7183\n",
      "Epoch 99/100\n",
      "50148/50148 [==============================] - 3s 57us/step - loss: 0.6059 - acc: 0.7741 - val_loss: 0.7041 - val_acc: 0.7183\n",
      "Epoch 100/100\n",
      "50148/50148 [==============================] - 3s 59us/step - loss: 0.6112 - acc: 0.7733 - val_loss: 0.7589 - val_acc: 0.7183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fa81ab5630>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=bins * 3 + 9, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(categories, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(XhistPlace, y, epochs=100, batch_size=128, validation_split=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1037  101   26  144  315  137   40]\n",
      " [ 188 1139    5  319   81   50   18]\n",
      " [   8    0 1780    0    0    0   12]\n",
      " [ 110  135    7 1184  325   23   16]\n",
      " [ 173   30   12  162 1357   45   21]\n",
      " [  51   10    1    6   13 1718    1]\n",
      " [  40    5   68   12  104    0 1571]]\n",
      "0.7766666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.6453018 , 0.80211268, 0.93733544, 0.64805692, 0.61822323,\n",
       "        0.8707552 , 0.935676  ]),\n",
       " array([0.57611111, 0.63277778, 0.98888889, 0.65777778, 0.75388889,\n",
       "        0.95444444, 0.87277778]),\n",
       " array([0.6087467 , 0.70745342, 0.96242228, 0.65288117, 0.67934919,\n",
       "        0.91068116, 0.90313308]),\n",
       " array([1800, 1800, 1800, 1800, 1800, 1800, 1800], dtype=int64))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XhistPlace_test = np.hstack((Xtest_hist, testPlaces))\n",
    "predict = model.predict(XhistPlace_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest.argmax(axis=1), predict.argmax(axis=1)))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(ytest.argmax(axis=1), predict.argmax(axis=1)))\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(ytest.argmax(axis=1), predict.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=bins * 3 + 9, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(16, activation='relu'))\n",
    "#model.add(Dense(8, activation='relu'))\n",
    "#model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(categories, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(XhistPlace, y, epochs=100, batch_size=512, validation_split=0.005)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
